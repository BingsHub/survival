{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and custom modules\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from rapidfuzz import process, fuzz\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "import survival.utils\n",
    "importlib.reload(survival.utils)\n",
    "from survival.utils import show_all\n",
    "from survival.utils import validate_imputation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_parquet(\"../../data/processed/raw_clean.parquet\")\n",
    "hh = pd.read_csv(\"../../data/processed/hh_clean.csv\")\n",
    "cities = pd.read_csv('../../data/processed/cities.csv')\n",
    "nl = pd.read_csv('../../data/processed/nl.csv')\n",
    "countries = pd.read_csv('../../data/processed/countries.csv')\n",
    "income = pd.read_csv('../../data/processed/income.csv')\n",
    "gemeenten = pd.read_csv('../../data/processed/gemeenten.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the earliest purchase date per performance, in case people bought multiple tickets at different times\n",
    "min_purchase_date = data.groupby(['id', 'start_date']).agg(\n",
    "    min_purchase_date =( 'purchase_date', 'min')).reset_index()\n",
    "\n",
    "data = data.merge(min_purchase_date, on=['id', 'start_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per id per start_date, count the amount of tickets bought and store in column 'order_size', and count per ticket type the amount of tickets bought and store in columns 'order_size_<ticket_type>'. fill with 0 if no tickets bought\n",
    "data['order_size'] = data.groupby(['id', 'start_date'])['id'].transform('count')\n",
    "data['total_order_value'] = data.groupby(['id', 'start_date'])['price'].transform('sum')\n",
    "data['avg_order_value'] = data.groupby(['id', 'start_date'])['price'].transform('mean')\n",
    "data['total_order_value'] = data['total_order_value'].round(2)\n",
    "data['avg_order_value'] = data['avg_order_value'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these, but perhaps drop ticket_num earlier -> figure out if its necessary in a grouping operation\n",
    "data = data.drop(columns=['ticket_num', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales = data.groupby(['start_date', 'purchase_date']).size().reset_index(name='tickets_sold')\n",
    "    \n",
    "# Calculate cumulative sales for each performance\n",
    "result = daily_sales.sort_values(['start_date', 'purchase_date'])\n",
    "result['cumulative_sales'] = result.groupby('start_date')['tickets_sold'].cumsum()\n",
    "\n",
    "result = result[[\n",
    "    'start_date',\n",
    "    'purchase_date',\n",
    "    'tickets_sold',\n",
    "    'cumulative_sales'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1608,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(result, on=['start_date', 'purchase_date'], how='left').drop(columns=['purchase_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1609,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove subscription tickets\n",
    "subscription_ticket = ['abo standaard', 'abo vk dno', 'abonnement 22/23', 'kassa abo standaard', 'abonnement 24/25', 'abo vk hnb', 'abo vrij']\n",
    "\n",
    "# remove all subscription tickets from activity\n",
    "data = data[~data['ticket_type'].isin(subscription_ticket)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete records where is_free == 1 and drop the column\n",
    "data = data[data['is_free'] != 1]\n",
    "data = data.drop('is_free', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all educatie tickets because these visitors are not unique\n",
    "data = data[~data['ticket_type'].str.contains('educatie')]\n",
    "\n",
    "# drop all ticket where ticket_type are related to employees\n",
    "employee_ticket = [\n",
    "    'zoekplaats',\n",
    "    'huiskorting',\n",
    "    'medewerker',\n",
    "    'medewerker no&b',\n",
    "    'vrijplaats',\n",
    "    'paniek',\n",
    "    'balletorkest',\n",
    "    'orkest',\n",
    "    'nedpho'\n",
    "    ]\n",
    "\n",
    "data = data[~data['ticket_type'].isin(employee_ticket)]\n",
    "\n",
    "# drop all records where email contains @operaballet.nl\n",
    "data = data[data['email'].notna() & ~data['email'].str.contains('@operaballet.nl', na=False)]\n",
    "\n",
    "# drop the following ids because they are related to employees, institutions or groups\n",
    "from survival.constants import nonvisitor_ids\n",
    "data = data[~data['id'].isin(nonvisitor_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1612,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(\n",
    "    data.groupby(['id', 'start_date', 'ticket_type'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .add_prefix('tickets_type_'), \n",
    "    on=['id', 'start_date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ticket_type column\n",
    "data = data.drop(columns='ticket_type')\n",
    "\n",
    "# group by id and start_date and remove duplicates\n",
    "data = data.drop_duplicates(subset=['id', 'start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1614,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['total_order_value'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1615,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['season'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map opera and ballet\n",
    "data['artform'] = data['artform'].map({'opera': 1, 'ballet': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data by id and min_purchase_date'])\n",
    "data = data.sort_values(by=['id', 'min_purchase_date'])\n",
    "\n",
    "# group by id and get the first 5 min_purchase_date']) values\n",
    "data = data.groupby('id').head(5)\n",
    "\n",
    "# Create a column for the purchase number\n",
    "data['purchase_number'] = data.groupby('id').cumcount() + 1\n",
    "\n",
    "# pivot the data to get each purchase's order value as a separate column\n",
    "pivot_data_avg_order_value = data.pivot(index='id', columns='purchase_number', values='avg_order_value')\n",
    "pivot_data_total_order_value = data.pivot(index='id', columns='purchase_number', values='total_order_value')\n",
    "\n",
    "# rename the columns for clarity\n",
    "pivot_data_avg_order_value.columns = [f'avg_order_value_{col}' for col in pivot_data_avg_order_value.columns]\n",
    "pivot_data_total_order_value.columns = [f'total_order_value_{col}' for col in pivot_data_total_order_value.columns]\n",
    "\n",
    "# merge back with the original data if you need to keep other columns\n",
    "data = data.merge(pivot_data_avg_order_value, on='id', how='left')\n",
    "data = data.merge(pivot_data_total_order_value, on='id', how='left')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/94p4d0y142132_pd6nn9gqc40000gn/T/ipykernel_73292/509915056.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.loc[data['artform'] == 0, 'rank'] = data.loc[data['artform'] == 0, 'rank'].replace(ballet_rank_replace_dict)\n",
      "/var/folders/_f/94p4d0y142132_pd6nn9gqc40000gn/T/ipykernel_73292/509915056.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.loc[data['artform'] == 1, 'rank'] = data.loc[data['artform'] == 1, 'rank'].replace(opera_rank_replace_dict)\n"
     ]
    }
   ],
   "source": [
    "ballet_rank_replace_dict = {\n",
    "    'premium': 1,\n",
    "    'rang 1': 2,\n",
    "    'rang 2': 3,\n",
    "    'rang 3': 4,\n",
    "    'rang 4': 5,\n",
    "    'rang 5': 6,\n",
    "    'rang 6': 7\n",
    "}\n",
    "\n",
    "opera_rank_replace_dict = {\n",
    "    'rang 1': 1,\n",
    "    'rang 2': 2,\n",
    "    'rang 3': 3,\n",
    "    'rang 4': 4,\n",
    "    'rang 5': 5,\n",
    "    'rang 6': 6,\n",
    "    'rang 7': 7\n",
    "}\n",
    "\n",
    "# if artform = 0, replace the rank values with the ballet rank values\n",
    "data.loc[data['artform'] == 0, 'rank'] = data.loc[data['artform'] == 0, 'rank'].replace(ballet_rank_replace_dict)\n",
    "\n",
    "# if artform = 1, replace the rank values with the opera rank values\n",
    "data.loc[data['artform'] == 1, 'rank'] = data.loc[data['artform'] == 1, 'rank'].replace(opera_rank_replace_dict)\n",
    "\n",
    "# create dummy variables for rank where artform = 0 (ballet) and artform = 1 (opera), name the columns accordingly\n",
    "#ballet_dummies = pd.get_dummies(data.loc[data['artform'] == 0, 'rank'], prefix='ballet_rank', dtype=int)\n",
    "#opera_dummies = pd.get_dummies(data.loc[data['artform'] == 1, 'rank'], prefix='opera_rank', dtype=int)\n",
    "\n",
    "# get dummies for rank\n",
    "dummies = pd.get_dummies(data['rank'], prefix='rank_', dtype=int).fillna(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lead days feature\n",
    "data['lead_days'] = (data['start_date'] - data['min_purchase_date']).dt.days\n",
    "\n",
    "# retain only lead days that are 0 or above\n",
    "data = data[data['lead_days'] >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create next_purchase_date and time columns\n",
    "data['next_purchase_date'] = data.groupby('id')['min_purchase_date'].shift(-1)\n",
    "data['time'] = (data['next_purchase_date'] - data['min_purchase_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age at time of purchase\n",
    "data['age_at_purchase'] = (data['min_purchase_date'] - data['birthdate']).dt.days / 365.25\n",
    "data['age_at_purchase'] = data['age_at_purchase'].apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns 'age_under_18', 'age_18_35', 'age_36_55', 'age_over_55' and fill with 0\n",
    "data['age_under_18'] = 0\n",
    "data['age_18_35'] = 0\n",
    "data['age_36_55'] = 0\n",
    "data['age_over_55'] = 0\n",
    "data['age_unknown'] = 0\n",
    "data['age_other'] = 0\n",
    "\n",
    "\n",
    "data.loc[(data['age_at_purchase'] < 18) & (data['age_at_purchase'] > 10), 'age_under_18'] = 1\n",
    "data.loc[(data['age_at_purchase'] >= 18) & (data['age_at_purchase'] <= 35), 'age_18_35'] = 1\n",
    "data.loc[(data['age_at_purchase'] >= 36) & (data['age_at_purchase'] <= 55), 'age_36_55'] = 1\n",
    "data.loc[data['age_at_purchase'] > 55, 'age_over_55'] = 1\n",
    "data.loc[data['age_at_purchase'].isnull(), 'age_unknown'] = 1\n",
    "data.loc[(data['age_at_purchase'] < 8) | (data['age_at_purchase'] > 99), 'age_other'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variables for country code if nl or not, email if provided or not, if municipality is provided or not, if city if provided or not\n",
    "data['is_nl'] = (data['country_code'] == 'nl').astype(int)\n",
    "data['email_provided'] = data['email'].notna().astype(int)\n",
    "data['municipality_provided'] = data['municipality'].notna().astype(int)\n",
    "data['city_provided'] = data['city'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1625,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_purchase_date = data['min_purchase_date'].max()\n",
    "data['days_since_first_purchase'] = (max_purchase_date - data['min_purchase_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get month of year and day of week of start_date and min_purchase_date\n",
    "data['start_month'] = data['start_date'].dt.month\n",
    "data['start_dayofweek'] = data['start_date'].dt.dayofweek\n",
    "\n",
    "data['purchase_month'] =  data['min_purchase_date'].dt.month\n",
    "data['purchase_dayofweek'] = data['min_purchase_date'].dt.dayofweek\n",
    "\n",
    "# dict for mapping dayofweek\n",
    "dayofweek_map = {\n",
    "    0: 'monday',\n",
    "    1: 'tuesday',\n",
    "    2: 'wednesday',\n",
    "    3: 'thursday',\n",
    "    4: 'friday',\n",
    "    5: 'saturday',\n",
    "    6: 'sunday'\n",
    "}\n",
    "\n",
    "month_map = {\n",
    "    1: 'january',\n",
    "    2: 'february',\n",
    "    3: 'march',\n",
    "    4: 'april',\n",
    "    5: 'may',\n",
    "    6: 'june',\n",
    "    7: 'july',\n",
    "    8: 'august',\n",
    "    9: 'september',\n",
    "    10: 'october',\n",
    "    11: 'november',\n",
    "    12: 'december'\n",
    "}\n",
    "\n",
    "# map start_month, start_dayofweek, purchase_month, purchase_dayofweek to dayofweek_map and month_map\n",
    "data['start_month'] = data['start_month'].apply(lambda x: month_map.get(x, None))\n",
    "data['start_dayofweek'] = data['start_dayofweek'].apply(lambda x: dayofweek_map.get(x, None))\n",
    "\n",
    "data['purchase_month'] = data['purchase_month'].apply(lambda x: month_map.get(x, None))\n",
    "data['purchase_dayofweek'] = data['purchase_dayofweek'].apply(lambda x: dayofweek_map.get(x, None))\n",
    "\n",
    "# get dummies for start_month, start_dayofweek, purchase_month, purchase_dayofweek\n",
    "data = pd.get_dummies(data, columns=['start_month', 'start_dayofweek', 'purchase_month', 'purchase_dayofweek'], dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies just for male and female\n",
    "data['gender_male'] = (data['gender'] == 'male').astype(int)\n",
    "data['gender_female'] = (data['gender'] == 'female').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the location from municipalities, cities, and then countries (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first_start date of each production should be 1 since it is the first performance of the production, indicating premiere status\n",
    "# flirt should remain 0 \n",
    "data['is_premiere'] = data.groupby('production')['start_date'].transform('min')\n",
    "data['is_premiere'] = (data['start_date'] == data['is_premiere']).astype(int)\n",
    "data.loc[data['production'].str.contains(' flirt', case=False, na=False), 'is_premiere'] = 0\n",
    "\n",
    "data['is_flirt'] = data['production'].str.contains(' flirt', case=False, na=False).astype(int)\n",
    "\n",
    "# remove ' flirt' from production name\n",
    "data['production'] = data['production'].str.replace(' flirt', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vila</td>\n",
       "      <td>42.53176</td>\n",
       "      <td>1.56654</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sispony</td>\n",
       "      <td>42.53368</td>\n",
       "      <td>1.51613</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sant julia de lòria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213594</th>\n",
       "      <td>banket</td>\n",
       "      <td>-17.38333</td>\n",
       "      <td>30.40000</td>\n",
       "      <td>zw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213595</th>\n",
       "      <td>epworth</td>\n",
       "      <td>-17.89000</td>\n",
       "      <td>31.14750</td>\n",
       "      <td>zw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213596</th>\n",
       "      <td>chitungwiza</td>\n",
       "      <td>-18.01274</td>\n",
       "      <td>31.07555</td>\n",
       "      <td>zw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213597</th>\n",
       "      <td>harare western suburbs</td>\n",
       "      <td>-17.84150</td>\n",
       "      <td>30.87674</td>\n",
       "      <td>zw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213598</th>\n",
       "      <td>mhangura mine</td>\n",
       "      <td>-16.89196</td>\n",
       "      <td>30.15902</td>\n",
       "      <td>zw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213599 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  latitude  longitude country_code\n",
       "0                         vila  42.53176    1.56654           ad\n",
       "1                       soldeu  42.57688    1.66769           ad\n",
       "2                      sispony  42.53368    1.51613           ad\n",
       "3                    el tarter  42.57952    1.65362           ad\n",
       "4          sant julia de lòria  42.46372    1.49129           ad\n",
       "...                        ...       ...        ...          ...\n",
       "213594                  banket -17.38333   30.40000           zw\n",
       "213595                 epworth -17.89000   31.14750           zw\n",
       "213596             chitungwiza -18.01274   31.07555           zw\n",
       "213597  harare western suburbs -17.84150   30.87674           zw\n",
       "213598           mhangura mine -16.89196   30.15902           zw\n",
       "\n",
       "[213599 rows x 4 columns]"
      ]
     },
     "execution_count": 1629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from survival.utils import geonames_cleaner\n",
    "geonames_cleaner(data, ['city', 'municipality'])\n",
    "geonames_cleaner(nl, ['name'])\n",
    "geonames_cleaner(hh, ['municipality'])\n",
    "geonames_cleaner(gemeenten, ['oude_naam', 'nieuwe_naam'])\n",
    "geonames_cleaner(cities, ['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get all Dutch cities from the data\n",
    "dutch_cities = data[data['country_code'] == 'nl']\n",
    "\n",
    "# Create a clean mapping of city names to coordinates from nl dataset\n",
    "city_coords = nl[['name', 'latitude', 'longitude']].drop_duplicates(subset=['name']).loc[~(nl['alternatenames'].isnull() & nl['name'].duplicated())]\n",
    "\n",
    "# Merge the coordinates with the Dutch cities\n",
    "data = data.merge(\n",
    "    city_coords,\n",
    "    left_on='city',\n",
    "    right_on='name',\n",
    "    how='left'\n",
    ").drop(columns='name')\n",
    "\n",
    "# Check which cities are missing coordinates\n",
    "missing_cities = data[\n",
    "    (data['country_code'] == 'nl') & \n",
    "    (data['longitude'].isna()) & \n",
    "    (data['city'].notna())\n",
    "]['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities still missing: 887\n",
      "Still missing cities: ['s gravenhage' 'breukelen ut' 'noordwijk zh' 'ede gld' 'valkenburg lb'\n",
      " 'hengelo ov' 'elsloo lb' 'capelle a/d shissel' 'katwijk zh' '242' '232'\n",
      " 'ijsselstein ut' '627234370' 'rijswijk zh' 'spijkerboor nh' 'nijkerk gld'\n",
      " 'vianen ut' 'heusden gem heusden' 'stuttgart' 'amsterdaam' 'laren nh'\n",
      " 'vooburg' 'boy@easyshootsnl' '65 58' 'elst gld' '929' '15' 'buren gld'\n",
      " '/ s gravenhage' '33' 'beek berg en dal' 'amerpoort' '4' 'vienna'\n",
      " 'laan op zuid' '2102zr' 'vianen u' 'cotignac   france'\n",
      " 'nieuwerkerk ad ijssel' 'oosterhout nb' 'voorschotten' 'velp gld'\n",
      " 'beets nh' 'loenen gld' 'midden beemster' 'molenhoek lb' 'enkuizen'\n",
      " 'sleenaken' 'nieuw vannep' 'ede / the netherlands' 'anna palowna'\n",
      " 'amstertdam' 'oudorp nh' 'loenen a/d vecht' 'alphen gld' 'aalst waalre'\n",
      " 'wyk by duurstede' 'sofia' 'katwyk zh' 'vianen ut nederland'\n",
      " 'kapel avezaath buren' 'des haag' 'valkenburg zh' 'antwerpen' 'brussel'\n",
      " 'cappele aan de ijssel' 'seeheim jugenheim' 'westerhaar vriezenv wijk'\n",
      " 'almere036 53' '20' 'winsum gn' 'spykenisse' 'nieuwendijk nb'\n",
      " 'vinkeveen nl' 'almera' 'well lb' 'den haag the netherlands' 'al ere'\n",
      " 'amsterdam zo' 'laren gld' 'driebergen   rijsenburg'\n",
      " 'cappelle aan den ijssel' 'beek ubbergen' 'lelystand' 'amsterdam   zo'\n",
      " 'krakenburg' '33hs' 'st augustine' 'the hague nl' 'reewijk'\n",
      " 'graft de rijp' 'koog a/d zaan' '358' 'bunschoten spakenburg' 'mexico'\n",
      " 'stpancras' '2' 'rotteerdam' 'amsetrdam' 'annapaulowna' 'wilp gld'\n",
      " 'ussum' 'amstersam' 'stavanger' 'drassburg' 'grevesmuhlen'\n",
      " 'amsterdam   schiphol ams netherlands' 'veenendaaal' 'paris' '1'\n",
      " 'ouderkerk aan de amste' 'bunnink' '0206947540amsterdam'\n",
      " 'court st etienne' 'huis ter heide ut' 'alphen aan den rtijn'\n",
      " 'lissebroek' 'kleve' 'ylst' 'den hoorn texel' 'noordwijker'\n",
      " 'arnhem0641827976' 'berlicum nb' 'state college' 'well gld' 'baarlo ov'\n",
      " 'rijswijk0650627059' 'den hoorn zh' 'utrecht area netherlands'\n",
      " 'voorstonden brummen' 'trondheim' 'alphen nb' 'hellevoetsluit'\n",
      " 'oudebildtzijl' 'oostwold gem oldambt' 'utrechr' 'delft nederland'\n",
      " 'neu reisenberg' '`s gravenhage' 'caplle a/d/ ijssel' 'st michielsgestel'\n",
      " 'stad' 'waarle' 'voorzchoten' 'noord brabant' 'urecht' 'halfweg nh'\n",
      " 'nul part' 'odessa' 'ouderkerk adijssel' 'lepelstraatnb' 'bergen lb'\n",
      " 'driebergen rijisanburg' 'bergenop zoom' 'zuidwolde dr' 'gfcfxfdxdfy'\n",
      " 'beek lb' 'ooosterhout' 'amserdam' 'bbaarn' 'ouderamstel' 'vianen/ut'\n",
      " 'rijswijk zh the netherlands' 'doetinhem' 'linde dr' 'oud zuylen'\n",
      " 'ouder a/d amstel' 'zevenhuizen zh' 'monnickedam' '1056bn amsterdam'\n",
      " 'dusseldorf' 'hoorn terschelling' 'zaporoz' 'bergen n h' 'bisschopsweg'\n",
      " 'scherpenzeel gld' '24 mrt' 'koln' 'broek op lamgedijk' 'oudemolen dr'\n",
      " '141' 'duivendreht' 'santpoort z' 'duivedrecht' 'kessel lb' 'hp'\n",
      " 'rottterdam' 'hoofdorp' 'alsterdam' '3971 cz driebergen' 'amterdam'\n",
      " 'hoofddrop' '1024 ez' 'ouddorp zh' 'almere hout' 'oosterhout gld'\n",
      " 'leystad' '57a' 'amsterdam nh' '3040' 'wasssenaar' 'huisse' 'rubenstraat'\n",
      " 'baarlo lb' 'pumerend' '89 3l' 'noordwijk gn' 'amsterdam netherlands'\n",
      " '3020' 'oirscot' 'rijswijk gld' 'zuid holland' '3' 'noordwyk zh'\n",
      " 'courbetstraat' '1442' '?s gravenhage' 'capelle ad ijssel' 'rottetdam'\n",
      " 'amersforot' 'hannover' 'rozenburg zh' 'utrecth' 'amsrerdam' 'grenoble'\n",
      " 'hiambacht' 'akmaar' 'shipping mercurius 508 duivendrecht 1115'\n",
      " 'saint hilaire de riez' 'moscow' 'neuendorf' 'anjeveen' 'mainz'\n",
      " 'tilburg   niederlande' 'breukeken' 'aarle   rixtel' 'karlsruhe'\n",
      " 'st jacobiparochie' 'dirrietz' 'munich' '603' 'aagtdorp   schoorl'\n",
      " 'wichelen' 'sint michilelsgestel' 't zand nh' 'zennewijnwn' 'dublin'\n",
      " 'eindhovemn' '21' 'wijngaarden zh' 'zevwnhoven' 'noord holland'\n",
      " 'haasdrecht' 'ouderkerk aan de anstel' 'hilverusm' 'hazerswoudedorp'\n",
      " 'sgravenhage' 'praha 10' 'zandvoort aan zee' 'jar' '7'\n",
      " 'tienhoven aan de lek' 's hertogenosch' 'beetsterzwag' 'asmterdam'\n",
      " 'schiphol oost' '16a' '173' 'ouderkerk ad amstel' 'zulpich' 'ht'\n",
      " 'wenum wiesel' 'haren nb' 'milano' 'oudendijk nh' 'geesteren gld'\n",
      " 'katwijk z h' 'hazerswoude ryndyk' 'rotterdan' '3532ga' 'landmeer' 'home'\n",
      " 'lonender' 'scherpenzeel fr' 'p' 'amstelween' 'muiderberh' 'arnham'\n",
      " 'amaterdam' 'noordwolde fr' 'ansterdam' 'arnehm' 'amsterdfam'\n",
      " 'amsterdam city centre' 'rossum gld' 'amsterdamzuidoost' '?s heerenberg'\n",
      " 'shertogenbosch' 'amsterdam west' 'nederhorst ten berg' 'amsterdaqm'\n",
      " 'zaaandam' 'middelburg zld' 'alphen ad rijn' 'ijmuiden/niederlande'\n",
      " 'house place' '36' 'noordholland' 'amstleveen' 'leda' 'sdfdfg'\n",
      " 'tienhoven ut' 'zieirkzee' 'fritzlar' 'bergisch gladbach'\n",
      " 'villars sur glane' 'oost  west en middelbeers' 'austeritz' 'meulebeke'\n",
      " 'uccle' 'ellemeets' 'hilversum hilversum' 'berkel en rodernrijs'\n",
      " 'amsterdm' 'hengelo gelderland' 'venraay' 'ceintuurbaan' '51'\n",
      " 'amstelveer' 'planegg' 'langerak zh' '75006' 'berlin' 'st willebrord'\n",
      " 'hoofddirp' 'amsterdasm' 'afferden gld' 'hs' 'amsterdamamsterdam'\n",
      " 'frankfurt' 'maaren' 'oostrum lb' 'naarden vesting' 'bergwijkdreef'\n",
      " 'harderwijk gld' '1079 vr' 'gl amsterdam' 'oosterhout nl' '3706ve'\n",
      " 'amsterdamm' 'the student hotel' 'leidem' 'heemstede nh' 'ter aae'\n",
      " 'willemstad nb' 'sint pancras nh' 'oudemeerdum' 'ouderkerk ad ijssel'\n",
      " 'heerhogowaard' 'delden ov' 'amstelveeen' 'wirdum fr' 'bucuresti'\n",
      " 'st oedenrode' 'rijkswijk' 'haren gem haren' 'koog ad zaan' '40'\n",
      " 'alphen ad rujn' 'aartswod' 'voorst gem voorst' 't loo oldebroek'\n",
      " 'central' '56' 'dijkstraat' 'room 1343' 'united states' 'velo'\n",
      " 'zwolle ov' 'olathe' 'noord  scharwoude' '204' 'netherland'\n",
      " 'oudega gem smallingerlnd' 'wassenar' 'hengelo gld' 'wien' 'darmstadt'\n",
      " 'stockholm' 'hoofddorpstill' '48c' 'nijmegen the netherlands' 'usa'\n",
      " 'santpooort zuid' 'oosterwolde fr' '6573ck beek ubbergen' 'zuidwolde gn'\n",
      " 'makkum fr' 'beuningen ov' '638' 'velp nb' 'bordeaux' 'rhhon'\n",
      " 'broek op langedyk' 'utrect' '2497cs' 'diemen noord' '?s hertogenbosch'\n",
      " 'amsterdamj' 'bennenbroek' 'dean haag' 'parijs' 'vooorburg' 'de zwaag'\n",
      " 'amstlveen' 'amstersdam' 'de meren' 'veenedaal' 'heusden gem asten'\n",
      " 'amsterdam noord' 'amsterdam science park' 'metslawier' 'd'\n",
      " 'den haag nederland' 'nieuwdorp zld' '12' '`hoorn' 'denhelder'\n",
      " 'an=msterdam' 'amsteredam' 'ríjswijk' 'steenbergen nb' 'aachen'\n",
      " 'oosterend nh' 'purmerend nederland' 'bllthoven' 'heehugowaard' 'lanaken'\n",
      " 'stmichielsgestel' 'amsterdsm' 'brussels' 'varna' 'wasenaar'\n",
      " 'oudega sudwest fryslan' 'cologne' 'x' '1445 rw purmerend'\n",
      " 'heist op den berg' 'la salvetat st gilles' '3533 ck utrecht' 'yes'\n",
      " 'amsterd' 'winsum gr' 'oegsgeest' 'denhaag' 'oostwold westerkwartier'\n",
      " '27' '48b1' 'apedoorn' 'jougne' 'noord   scharwoude' 'en bosch'\n",
      " 'zwijndrechf' 'onbekend' 'amsterxam' '7hs' 'haenwijck' '119' 'pernis rt'\n",
      " 'budapest' '31' 'portugaal' 'nes ameland' 'uihoorn' 'wassenaaar' 'ziest'\n",
      " 'lecce' 'am sterdam' 'rijwijk' '2b' '5405' 'hoghheim' 'delftgauw'\n",
      " 'almwew' 'purmerand' 'bussum 46' 'prumerend' 'noordwolde gn'\n",
      " 'heer arendskerke' 'maasteicht' 'bos en duin' 'kcokengen' 'de kwakewl'\n",
      " 'amsterdam/nh' '106' 'nieuwerkerk aan den i jsssl' 'oss nb' 'princeton'\n",
      " '197' 'london' 'elst u' 'sheer hendrikskinderen' 'iasi'\n",
      " 'amsterdam the netherlands' 'st annaparochie' 'washington dc' '13i'\n",
      " '5251 aa' 'rotterrdam' 'zuid oost beemster' 'diemen amsterdam'\n",
      " 'kampen ov' 'maatricht' '206' 'utrechts' 'crailo huizen' '2352he'\n",
      " 'rijswijk nb' 'hilversem' 'veenwouden' 'laren n h' 'bumschoten'\n",
      " 'amsteradm' 'dortmund' 'monickendam' 'potomac' 'erfurt' 'nieuwe gein'\n",
      " 'kuala lumpur' 'berkel en rodenrys' 'haarle gem hellendoorn' '3582pn'\n",
      " '14' 'bodø' 'eindhoevn' 'corantijnstraat 26 santpoort' 'frankenthal'\n",
      " 'cornelis krusemanstraat' 'amsterdam z o' 'hoofdoorp' 'utrechy'\n",
      " 'ouderker aan de amstel' 'ouderkerk a:d amstel' '1091kw' 'meerijnen'\n",
      " 'loenen a/de vecht' 'dinteloord gemeente steenbergen' 'beunigen'\n",
      " 'edinburgh' '178' 'hoek v holland' 'wb harderwijk' 'jr amsterdam'\n",
      " 'cm den haag' '06 154 27028' 'wijterswijk' 'amsteveen'\n",
      " 'aderkerk aan de amstel' 'amsterdam centrum' 'elstu' 'aalst gld'\n",
      " 'dan haag' '78' 'zwaag06' 'valkenburg z h' 'oudheuseden' 'den hague'\n",
      " '129' '45' 'amtsterdam' 'stadhouderskade 25' 'waalwijkl'\n",
      " 'krimpen ad ijssel' 'k1' 'ysselstein' 'milahvanstrijp@hotmailcom'\n",
      " 'almerepoort' 'amersforrt' 'eennes' 'dubai' 'broekland ov'\n",
      " 'santiago de compostela' 'halver' 'liverpool' '147' 'krimpen a/d ijsel'\n",
      " 'hilversume' 'zwolle netherlands' 'amstelhoejk' 'wolphaartsdij' 'madrid'\n",
      " 'oost  souburg' 'hilversun' 'jan van galenstraat 335 1061 az amsterd'\n",
      " 'nannet' 'doorneburg' 'bilthoen' 'sint pancreas' 'schondorf' '44'\n",
      " 'zeeburg' 'santpoort noord gemeente velsen' 'uppsala' 'alkmaar`'\n",
      " 'strasslach' 'loenen ad vecht' 'oostgraftdijk' 'mullheim a/d ruhr'\n",
      " 'vledderveen gn' 'fern park' '9686ra beerta' 'nieuws vennep'\n",
      " 'staten island' 'en haag' 'amstrerdam' 'valbonne' 'utrecht netherlands'\n",
      " 'amsterdam nieuw west' 'moontfort' 'klosters' 'hamburg' 'burgh raamstede'\n",
      " '697' 'stjansklooster' 'bonn' 'alpen aan den rijn' 'amsyterdam'\n",
      " 'dordrecht nederland' 'nieuwegine' 'tienhoven zh' 'valkesnwaard'\n",
      " 'valkenburg a/d geul' 'anmsterdam' 'nijmegenlent' 'den hout nb'\n",
      " 'vledderveen dr' 'winter park' 'zevenhuizen gn' 'wijk bij duurs'\n",
      " 'hilkversum' '2101kh heemstede' 'castrcium' 'maarrssen'\n",
      " 'leidschendam voorburg' 'kumtich' '`s gravendeel'\n",
      " 'amsterdam   niederlande' 'amsterdam nederland' 'hong kong'\n",
      " 'naardenvesting' 'shavano park texas usa' 'lage vuusrche'\n",
      " 'alphen a/d rhijn' 'noordwijk z h' 'noordeinde nh' 'atyrau'\n",
      " 'eerste ringdijkstraat' 'beregen' 'santpoortzuid' 'den hasg'\n",
      " 'amstelvceen' 'alkmaar072' '1190' 'potsdam' 'volgograd' 'stephanskirchen'\n",
      " 'amsterdam / the netherlands' 'saint petersburg' 'amsterdam zuid oost'\n",
      " 'spijk gem lingewaal' 'roelofarerndsveen' 'nieuw  vennep' 'rijswijk z h'\n",
      " 'amsteram' 'nes gem boarnsterhim' '33a' 'e' 'nijmegen lent'\n",
      " 'serooskerke walcheren' 'loosdrecht nederland' 'rueil mal maison'\n",
      " 'burgh   haamstede' 'ydwinezanstra@gmailcom' 'borgerhout' 'doornburg'\n",
      " 'zandaam' 'blaricum/nederland' 'harenb' 'duivendrech' 'amsterdam06225271'\n",
      " '1016gj' 'utrcht' '132' 'breukelem' 's hertogenboavh'\n",
      " 'wageningen/niederlände' 'hengelo gdl' 'schipol' 'hellevoetssluis'\n",
      " 'nijmegem' 'lisboa' '1087 hj amsterdam' 'hvijfhuizen' 'casricum'\n",
      " 'langelo dr' 'busssum' 'bverwijk' 'seattle' 'leusdem' 'babberigh'\n",
      " '1021nk' 'bitlhoven' 's gravenhague' 'zandpoort zuid' 'the hageu' 'none'\n",
      " 'sandpoort' 'broek oplangedijk' 'rembrandt plain' 'utrecht / zeist'\n",
      " 'not specified' 'asterdam' 'zoetemeer' 'darlingstraat' 'schaerbeek'\n",
      " 'st nicolaasga' 'ijssesltein' 'berkhoven' 'wilns' 'zesit' 'oenen' 'ak'\n",
      " 'lommel' 'den ham ov' ':leiden' 'oosterhou' '1053vn amsterdam'\n",
      " 'leleystad' 'de bildt' 'haasten' 'hoyuten' 'below' 'spanbroel' 'xx'\n",
      " 'cp$716049048' '632' 'blariucm' 'nieuwerbrug a/d rijn'\n",
      " 'zuider tuindorpslaan 3 haarlem' 'landmseer' 'straats' 'niewe ter aa'\n",
      " 'brooklyn' 'berkel & rodenrijs' 'broek in waterlan' 'hoofdddorp'\n",
      " 'wolvwga' 'loosdrect' '?s graveland' 'amstelhoeck' 'beetserwaag'\n",
      " 'amsterdam amsterdam' 'elk grove village' 'leidrn' 'zwoille'\n",
      " 'vaassen gem epe' 'houston' '1171 cn badhoevedorp' 's gravenhagen'\n",
      " 'ripselaan' 'haarlme' 'breukelen nederland' '2265 dh' 'udn'\n",
      " 'neck wijdewormer' 'hilversumf' 'heiliglandstichting' 'fleuten'\n",
      " 'hengelo o' 'amssterdam' 'valkenburg ad geul' 'soesteberg' 'heemskek'\n",
      " 'vaarssen' 'mullingen aan de rijn' 'rotteredam' 'etten gld'\n",
      " 'ijsselstein utr' 'sloten fr' 'westgraftdijk' 'ravel residence'\n",
      " 'oegstgeeest' 'lang' 'denderhoutem' 'zevenbergschenhoek' 'oudemolen nb'\n",
      " 'vianen zh' 'ouderkerk a/d/ amstel' 'zwole' 'stein lb' 'middelberg'\n",
      " 'monsheim' 'woonplaats' '354' '22' 'the haag' 'emmen drenthe'\n",
      " 'russian federation' 'amsterdamnetherlands' 'tijjnje' 'beegdeb'\n",
      " 'westerstraat 79 amsterdam' 'aasterdam' 'amsterveen' 'oosterhoutnb'\n",
      " '1 hoog' '#naam?' 'hilden' '' 'a 3k' 'bamberg' '1071lz' 'helsinki'\n",
      " '?s gravenzande' 'b4' 'hil versum' 'de waterdief' 'amstelveen zuid'\n",
      " 'serooskerke gem veere' '¿¿¿¿' '34' 'urtrecht' 'wilhelminastraat 195h'\n",
      " 'nvt' 'den hogh' 'romania' 'herrliberg' 'amersham' 'wagenigen' 'dresden'\n",
      " 'ek' 'g' 'schaarbeek' 'amste' 'amst' 'eindhovwn' '72' '245' 'heukelom nb'\n",
      " 'kerk avezaath tiel' 'upsilon' 'oldemare' 'westerlee gn'\n",
      " 'nes gem heerenveen' 'h' 'zandvoort nh' 'nes noardeast fryslan'\n",
      " 'snekkersten' 'amsterdam   the netherlands' 'bears fr' 'rossum ov'\n",
      " 'miraflores' 'er' 'veenenedaal' 'bocholt' 'leersun'\n",
      " 'ouderkerk aan deamstel' 'bboxtel' 'steense' 'almere centrum'\n",
      " 'amsterdam oost' 'luyksgestel nb' 'leefdaal' 'cruquis' 'blitterswyck'\n",
      " 'steenbergen dr' '128 4' 'b' 'dansendam' 'woerdent' 'hoorn fr' '4 2'\n",
      " 'beek gem berg en dal' 'epenerbroekermeer' 'winsum fr' 'elsloo fr'\n",
      " '1075vk']\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping alternative names to the main city name\n",
    "alt_names_dict = {}\n",
    "for _, row in nl.iterrows():\n",
    "    if isinstance(row['alternatenames'], str):  # Check if alternatenames exists\n",
    "        alt_names = row['alternatenames'].split(',')\n",
    "        geonames_cleaner(pd.DataFrame(alt_names, columns=['name']), ['name'])\n",
    "        for alt_name in alt_names:\n",
    "            alt_names_dict[alt_name] = row['name']\n",
    "\n",
    "# For cities still missing coordinates, try matching through alternative names\n",
    "for city in missing_cities:\n",
    "    if city in alt_names_dict:\n",
    "        # Get the main name for this city\n",
    "        main_name = alt_names_dict[city]\n",
    "        \n",
    "        # Get coordinates from the main name\n",
    "        coords = nl[nl['name'] == main_name][['latitude', 'longitude']].iloc[0]\n",
    "        \n",
    "        # Update the coordinates in the main dataframe\n",
    "        mask = (data['country_code'] == 'nl') & (data['city'] == city)\n",
    "        data.loc[mask, 'latitude'] = coords['latitude']\n",
    "        data.loc[mask, 'longitude'] = coords['longitude']\n",
    "\n",
    "# Check remaining missing cities\n",
    "still_missing = data[\n",
    "    (data['country_code'] == 'nl') & \n",
    "    (data['longitude'].isna()) & \n",
    "    (data['city'].notna())\n",
    "]['city'].unique()\n",
    "\n",
    "print(f\"Number of cities still missing: {len(still_missing)}\")\n",
    "print(\"Still missing cities:\", still_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities still missing after fuzzy matching: 133\n",
      "Final missing cities: ['242' '232' '627234370' 'stuttgart' 'boy@easyshootsnl' '65 58' '929' '33'\n",
      " 'vienna' '2102zr' 'sofia' 'katwyk zh' '33hs' '358' 'mexico' 'stavanger'\n",
      " 'grevesmuhlen' 'nul part' 'odessa' 'gfcfxfdxdfy' 'zaporoz' '24 mrt'\n",
      " 'koln' '141' '1024 ez' '57a' '3040' '89 3l' '3020' '1442' 'hannover'\n",
      " 'moscow' 'neuendorf' 'mainz' 'karlsruhe' 'dirrietz' '603' 'dublin' '7'\n",
      " '16a' '173' 'zulpich' '3532ga' 'lonender' 'arnehm' 'leda' 'sdfdfg'\n",
      " 'meulebeke' 'uccle' '75006' 'berlin' '1079 vr' '3706ve' '56' 'olathe'\n",
      " '204' 'darmstadt' 'stockholm' '48c' '638' 'rhhon' '2497cs' 'lanaken'\n",
      " 'varna' 'cologne' 'yes' '48b1' 'jougne' 'onbekend' '7hs' 'haenwijck'\n",
      " '119' 'lecce' '2b' '5405' '106' 'princeton' '197' 'iasi' 'washington dc'\n",
      " '13i' '206' '2352he' 'erfurt' 'kuala lumpur' '3582pn' 'bodø' '1091kw'\n",
      " '178' '06 154 27028' '78' '129' 'k1' 'dubai' '147' 'madrid' 'nannet'\n",
      " 'uppsala' '697' 'kumtich' '1190' 'stephanskirchen' '33a'\n",
      " 'ydwinezanstra@gmailcom' '1016gj' '132' 'lisboa' 'seattle' '1021nk'\n",
      " 'none' 'not specified' 'zesit' 'xx' 'cp$716049048' '632' 'brooklyn'\n",
      " 'leidrn' 'houston' '2265 dh' '354' '' '1071lz' 'b4' '¿¿¿¿' 'nvt'\n",
      " 'romania' 'dresden' '72' '245' 'upsilon' 'snekkersten' 'bears fr'\n",
      " '1075vk']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all possible names (main names and alternative names)\n",
    "main_names = nl['name'].unique()\n",
    "alt_names = nl['alternatenames'].dropna().str.split(', ').explode().unique()\n",
    "all_names = np.concatenate([main_names, alt_names])\n",
    "\n",
    "# Do fuzzy matching for still missing cities\n",
    "for city in still_missing:\n",
    "    # Get the best match\n",
    "    match = process.extractOne(city, all_names)\n",
    "    \n",
    "    if match[1] > 85:  # If confidence score is high enough\n",
    "        matched_name = match[0]\n",
    "        \n",
    "        # Case 1: Matched name is a main name in nl dataset\n",
    "        if matched_name in nl['name'].values:\n",
    "            coords = nl[nl['name'] == matched_name][['latitude', 'longitude']].iloc[0]\n",
    "            \n",
    "        # Case 2: Matched name is an alternative name\n",
    "        else:\n",
    "            # Find the main city name for this alternative name\n",
    "            main_city = nl[nl['alternatenames'].fillna('').str.contains(matched_name, regex=False)]['name']\n",
    "            if not main_city.empty:\n",
    "                coords = nl[nl['name'] == main_city.iloc[0]][['latitude', 'longitude']].iloc[0]\n",
    "            else:\n",
    "                continue  # Skip if we can't find the main city\n",
    "                \n",
    "        # Update coordinates in main dataframe\n",
    "        mask = (data['country_code'] == 'nl') & (data['city'] == city)\n",
    "        data.loc[mask, 'latitude'] = coords['latitude']\n",
    "        data.loc[mask, 'longitude'] = coords['longitude']\n",
    "\n",
    "# Final check for missing cities\n",
    "final_missing = data[\n",
    "    (data['country_code'] == 'nl') & \n",
    "    (data['longitude'].isna()) & \n",
    "    (data['city'].notna())\n",
    "]['city'].unique()\n",
    "\n",
    "print(f\"Number of cities still missing after fuzzy matching: {len(final_missing)}\")\n",
    "print(\"Final missing cities:\", final_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check where lon and lat is null but municipality is not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all names which contain gemeente\n",
    "nl_municipalities = nl[\n",
    "    (nl['alternatenames'].str.contains(' munici', na=False)) | \n",
    "    (nl['alternatenames'].str.contains('gemeente', na=False) |\n",
    "    (nl['name'].str.contains('gemeente', na=False)) | \n",
    "    (nl['feature_code'] == 'adm2'))\n",
    "    ]\n",
    "# since the municipality names in data omit the prefix, we delete it here too\n",
    "nl_municipalities.loc[nl_municipalities['name'].str.startswith('gemeente '), 'name'] = nl_municipalities['name'].str.replace('gemeente ', '')\n",
    "\n",
    "# change the old name of westvoorne to voorne aan zee in nl_municipalities \n",
    "nl_municipalities.loc[nl_municipalities['name'] == 'westvoorne', 'name'] = 'voorne aan zee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records still missing coordinates: 97\n"
     ]
    }
   ],
   "source": [
    "# Add municipality coordinates only where coordinates are still missing\n",
    "municipality_coords = nl_municipalities[['name', 'latitude', 'longitude']].rename(\n",
    "    columns={\n",
    "        'latitude': 'municipality_latitude',\n",
    "        'longitude': 'municipality_longitude'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Merge municipality coordinates\n",
    "data = data.merge(\n",
    "    municipality_coords,\n",
    "    left_on='municipality',\n",
    "    right_on='name',\n",
    "    how='left'\n",
    ").drop(columns='name')\n",
    "\n",
    "# Fill missing coordinates with municipality coordinates where available\n",
    "mask = data['longitude'].isna()\n",
    "data.loc[mask, 'longitude'] = data.loc[mask, 'municipality_longitude']\n",
    "data.loc[mask, 'latitude'] = data.loc[mask, 'municipality_latitude']\n",
    "\n",
    "# Clean up by dropping the temporary municipality coordinate columns\n",
    "data = data.drop(columns=['municipality_latitude', 'municipality_longitude'])\n",
    "\n",
    "# Check remaining missing coordinates\n",
    "still_missing = data[\n",
    "    (data['longitude'].isna()) & \n",
    "    (data['city'].notna()) &\n",
    "    (data['country_code'] == 'nl')\n",
    "]\n",
    "print(f\"Number of records still missing coordinates: {len(still_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1636,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcli = countries[countries['feature_code'] == 'pcli'].drop(columns=['name', 'feature_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask records that need country coordinates\n",
    "missing_coords_mask = (data['longitude'].isna()) & (data['country_code'].notna())\n",
    "\n",
    "# country coordinates mapping\n",
    "country_coords = pcli.set_index('country_code')[['latitude', 'longitude']]\n",
    "\n",
    "# update latitude and longitude\n",
    "data.loc[missing_coords_mask, 'latitude'] = (\n",
    "    data.loc[missing_coords_mask, 'country_code']\n",
    "    .map(country_coords['latitude'])\n",
    ")\n",
    "data.loc[missing_coords_mask, 'longitude'] = (\n",
    "    data.loc[missing_coords_mask, 'country_code']\n",
    "    .map(country_coords['longitude'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing countries by checking the feature_code starting with 'pcl' in countries and add long and lat to data\n",
    "missing_cc = data.loc[(data['longitude'].isna()) & (data['country_code'] != 'nl'), 'country_code'].unique()\n",
    "\n",
    "missing_countries = countries[\n",
    "\tcountries['country_code'].isin(missing_cc) & \n",
    "\tcountries['feature_code'].str.startswith('pcl', na=False)\n",
    "].drop_duplicates(subset='country_code')\n",
    "\n",
    "data.loc[\n",
    "\t(data['longitude'].isna()) & (data['country_code'].notna()), \n",
    "\t'longitude'\n",
    "] = data.loc[\n",
    "\t(data['longitude'].isna()) & (data['country_code'].notna()), \n",
    "\t'country_code'\n",
    "].map(missing_countries.set_index('country_code')['longitude'])\n",
    "\n",
    "data.loc[\n",
    "\t(data['latitude'].isna()) & (data['country_code'].notna()), \n",
    "\t'latitude'\n",
    "] = data.loc[\n",
    "\t(data['latitude'].isna()) & (data['country_code'].notna()), \n",
    "\t'country_code'\n",
    "].map(missing_countries.set_index('country_code')['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually look up the lat and long of american samoa and namibia\n",
    "american_samoa = (-14.23377, -169.47767)\n",
    "namibia = (-22.00000, 17.00000)\n",
    "\n",
    "# update the lat and long of american samoa and namibia\n",
    "data.loc[data['country_code'] == 'as', 'latitude'] = american_samoa[0]\n",
    "data.loc[data['country_code'] == 'as', 'longitude'] = american_samoa[1]\n",
    "\n",
    "data.loc[data['country_code'] == 'na', 'latitude'] = namibia[0]\n",
    "data.loc[data['country_code'] == 'na', 'longitude'] = namibia[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the distance of known longitude and latitude to nob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every lan and long, calculate the distance to the nob\n",
    "nob = (52.367608492466346, 4.901889580039182)\n",
    "\n",
    "data['distance_to_nob'] = data.apply(\n",
    "    lambda row: geodesic(nob, (row['latitude'], row['longitude'])).kilometers\n",
    "    if pd.notnull(row['latitude']) and pd.notnull(row['longitude']) else None,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary flag to indicate whether distance to nob is known\n",
    "data['nl_spatial_imputed'] = data['distance_to_nob'].isna().astype(int)\n",
    "\n",
    "# fill missing distances with the median of the distance of country_code nl\n",
    "data['distance_to_nob'] = data['distance_to_nob'].fillna(data[data['country_code'] == 'nl']['distance_to_nob'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the income from hh and match with data municipality\n",
    "data = data.merge(hh, left_on='municipality', right_on='municipality', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1643,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter Dutch records with valid coordinates\n",
    "nl_data = data[\n",
    "    (data['country_code'] == 'nl') & \n",
    "    data['latitude'].notna() & \n",
    "    data['longitude'].notna()\n",
    "]\n",
    "\n",
    "# Define features and target\n",
    "features = ['latitude', 'longitude', 'distance_to_nob']\n",
    "target = 'median_income'\n",
    "\n",
    "# Create the imputer\n",
    "imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        random_state=42,\n",
    "        max_depth=10  # Add depth limit to prevent overfitting\n",
    "    ),\n",
    "    random_state=42,\n",
    "    max_iter=10,\n",
    "    initial_strategy='mean'\n",
    ")\n",
    "\n",
    "# Prepare the data\n",
    "X = nl_data[features + [target]].copy()\n",
    "\n",
    "# Fit and transform\n",
    "X_imputed = imputer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running validation\n",
    "#results_df = validate_imputation(nl_data, features, target)\n",
    "#\n",
    "## Calculate confidence intervals\n",
    "#for metric in ['RMSE', 'MAE', 'R2', 'NRMSE']:\n",
    "#    mean = results_df[metric].mean()\n",
    "#    std = results_df[metric].std()\n",
    "#    ci = std * 1.96  # 95% ci\n",
    "#    print(f\"\\n{metric}:\")\n",
    "#    print(f\"Mean: {mean:.4f} ± {ci:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary flag to indicate whether the income is known and country_code == nl\n",
    "data['domestic_median_imputed'] = 0\n",
    "\n",
    "nl_missing_mask = (data['country_code'] == 'nl') & (data['median_income'].isna())\n",
    "data.loc[X.index, 'median_income'] = np.where(\n",
    "    nl_data['median_income'].isna(),\n",
    "    pd.DataFrame(X_imputed, columns=features + [target], index=X.index)['median_income'],\n",
    "    data.loc[X.index, 'median_income']\n",
    ")\n",
    "# flag for imputed nl records\n",
    "data.loc[nl_missing_mask, 'domestic_median_imputed'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation flag\n",
    "data['foreign_median_imputed'] = 0\n",
    "\n",
    "# fill non nl records with known country data\n",
    "non_nl_mask = (data['country_code'].notna()) & (data['country_code'] != 'nl') & (data['median_income'].isna())\n",
    "data.loc[non_nl_mask, 'median_income'] = data.loc[non_nl_mask, 'country_code'].map(\n",
    "    income.set_index('country_code')['median_income']\n",
    ")\n",
    "data.loc[non_nl_mask, 'foreign_median_imputed'] = 1\n",
    "\n",
    "# median of non nl records\n",
    "foreign_median = data.loc[(data['country_code'] != 'nl') & (data['median_income'].notna()), 'median_income'].median()\n",
    "\n",
    "# fill missing values with foreign median\n",
    "remaining_missing_mask = data['median_income'].isna()\n",
    "data.loc[remaining_missing_mask, 'median_income'] = foreign_median\n",
    "data.loc[remaining_missing_mask, 'foreign_median_imputed'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill records with no country code using nl median\n",
    "nl_median = data.loc[data['country_code'] == 'nl', 'median_income'].median()\n",
    "no_country_mask = data['country_code'].isna() & data['median_income'].isna()\n",
    "data.loc[no_country_mask, 'median_income'] = nl_median\n",
    "\n",
    "# mark as domestic median imputed\n",
    "data.loc[no_country_mask, 'domestic_median_imputed'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export full processed data for eda\n",
    "data.to_csv('../../data/processed/data_for_eda.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>country_code</th>\n",
       "      <th>email</th>\n",
       "      <th>municipality</th>\n",
       "      <th>city</th>\n",
       "      <th>production</th>\n",
       "      <th>start_date</th>\n",
       "      <th>artform</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>is_premiere</th>\n",
       "      <th>is_flirt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>distance_to_nob</th>\n",
       "      <th>nl_spatial_imputed</th>\n",
       "      <th>median_income</th>\n",
       "      <th>domestic_median_imputed</th>\n",
       "      <th>foreign_median_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>ljjschuurmans@gmail.com</td>\n",
       "      <td>delft</td>\n",
       "      <td>delft</td>\n",
       "      <td>22/23 turandot</td>\n",
       "      <td>2022-12-12 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00667</td>\n",
       "      <td>4.35556</td>\n",
       "      <td>54.854622</td>\n",
       "      <td>0</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>ljjschuurmans@gmail.com</td>\n",
       "      <td>delft</td>\n",
       "      <td>delft</td>\n",
       "      <td>22/23 messa da requiem</td>\n",
       "      <td>2023-02-13 20:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00667</td>\n",
       "      <td>4.35556</td>\n",
       "      <td>54.854622</td>\n",
       "      <td>0</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>eskersterneberg@gmail.com</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>21/22 made in amsterdam</td>\n",
       "      <td>2022-02-20 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1991-08-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>e.houtman@houthoff.com</td>\n",
       "      <td>None</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>22/23 the sleeping beauty</td>\n",
       "      <td>2022-12-27 19:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.434026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>joopmuller7@gmail.com</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>21/22 der freischutz</td>\n",
       "      <td>2022-06-18 19:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1939-06-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434708</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>linda.joep@casema.nl</td>\n",
       "      <td>None</td>\n",
       "      <td>houten</td>\n",
       "      <td>24/25 die fledermaus</td>\n",
       "      <td>2024-12-29 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1957-02-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.02833</td>\n",
       "      <td>5.16806</td>\n",
       "      <td>41.909596</td>\n",
       "      <td>0</td>\n",
       "      <td>48.684134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434709</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>f_duursema@hotmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>24/25 idomeneo</td>\n",
       "      <td>2025-02-15 19:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.434026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434710</th>\n",
       "      <td>4.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>mirna@upcmail.nl</td>\n",
       "      <td>None</td>\n",
       "      <td>weesp</td>\n",
       "      <td>24/25 die fledermaus</td>\n",
       "      <td>2024-12-10 19:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2003-10-31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.30750</td>\n",
       "      <td>5.04167</td>\n",
       "      <td>11.640816</td>\n",
       "      <td>0</td>\n",
       "      <td>34.573199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434711</th>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>jonathanebrito@gmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24/25 notenkraker en muizenkoning</td>\n",
       "      <td>2024-12-28 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.667152</td>\n",
       "      <td>1</td>\n",
       "      <td>69.338000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434712</th>\n",
       "      <td>3.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>sgoldienl@gmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>24/25 jewels</td>\n",
       "      <td>2025-03-01 20:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1973-11-25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.434026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141614 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rank country_code                      email municipality       city  \\\n",
       "0       1.0           nl    ljjschuurmans@gmail.com        delft      delft   \n",
       "1       2.0           nl    ljjschuurmans@gmail.com        delft      delft   \n",
       "3       2.0           nl  eskersterneberg@gmail.com    amsterdam  amsterdam   \n",
       "6       4.0           nl     e.houtman@houthoff.com         None  amsterdam   \n",
       "43      2.0           nl      joopmuller7@gmail.com    amsterdam  amsterdam   \n",
       "...     ...          ...                        ...          ...        ...   \n",
       "434708  1.0           nl       linda.joep@casema.nl         None     houten   \n",
       "434709  2.0           nl     f_duursema@hotmail.com         None  amsterdam   \n",
       "434710  4.0           nl           mirna@upcmail.nl         None      weesp   \n",
       "434711  3.0         None   jonathanebrito@gmail.com         None       None   \n",
       "434712  3.0           nl        sgoldienl@gmail.com         None  amsterdam   \n",
       "\n",
       "                               production          start_date  artform  \\\n",
       "0                          22/23 turandot 2022-12-12 20:00:00        1   \n",
       "1                  22/23 messa da requiem 2023-02-13 20:15:00        1   \n",
       "3                 21/22 made in amsterdam 2022-02-20 14:00:00        0   \n",
       "6               22/23 the sleeping beauty 2022-12-27 19:30:00        0   \n",
       "43                   21/22 der freischutz 2022-06-18 19:30:00        1   \n",
       "...                                   ...                 ...      ...   \n",
       "434708               24/25 die fledermaus 2024-12-29 14:00:00        1   \n",
       "434709                     24/25 idomeneo 2025-02-15 19:30:00        1   \n",
       "434710               24/25 die fledermaus 2024-12-10 19:30:00        1   \n",
       "434711  24/25 notenkraker en muizenkoning 2024-12-28 14:00:00        0   \n",
       "434712                       24/25 jewels 2025-03-01 20:15:00        0   \n",
       "\n",
       "         gender  birthdate  ...  gender_female is_premiere is_flirt  latitude  \\\n",
       "0       unknown 1999-03-23  ...              0           0        0  52.00667   \n",
       "1       unknown 1999-03-23  ...              0           0        0  52.00667   \n",
       "3        female 1991-08-11  ...              1           1        0  52.37403   \n",
       "6       unknown        NaT  ...              0           0        0  52.37403   \n",
       "43       female 1939-06-01  ...              1           0        0  52.37403   \n",
       "...         ...        ...  ...            ...         ...      ...       ...   \n",
       "434708   female 1957-02-06  ...              1           0        0  52.02833   \n",
       "434709  unknown        NaT  ...              0           0        0  52.37403   \n",
       "434710  unknown 2003-10-31  ...              0           0        0  52.30750   \n",
       "434711     None        NaT  ...              0           0        0       NaN   \n",
       "434712   female 1973-11-25  ...              1           0        0  52.37403   \n",
       "\n",
       "        longitude  distance_to_nob  nl_spatial_imputed  median_income  \\\n",
       "0         4.35556        54.854622                   0      29.600000   \n",
       "1         4.35556        54.854622                   0      29.600000   \n",
       "3         4.88969         1.095892                   0      33.400000   \n",
       "6         4.88969         1.095892                   0      33.434026   \n",
       "43        4.88969         1.095892                   0      33.400000   \n",
       "...           ...              ...                 ...            ...   \n",
       "434708    5.16806        41.909596                   0      48.684134   \n",
       "434709    4.88969         1.095892                   0      33.434026   \n",
       "434710    5.04167        11.640816                   0      34.573199   \n",
       "434711        NaN        24.667152                   1      69.338000   \n",
       "434712    4.88969         1.095892                   0      33.434026   \n",
       "\n",
       "        domestic_median_imputed  foreign_median_imputed  \n",
       "0                             0                       0  \n",
       "1                             0                       0  \n",
       "3                             0                       0  \n",
       "6                             1                       0  \n",
       "43                            0                       0  \n",
       "...                         ...                     ...  \n",
       "434708                        1                       0  \n",
       "434709                        1                       0  \n",
       "434710                        1                       0  \n",
       "434711                        0                       1  \n",
       "434712                        1                       0  \n",
       "\n",
       "[141614 rows x 195 columns]"
      ]
     },
     "execution_count": 1649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[((data['season_2021_2022'] == 1) |\n",
    "    (data['season_2022_2023'] == 1) |\n",
    "    (data['season_2023_2024'] == 1) |\n",
    "    (data['season_2024_2025'] == 1)) &\n",
    "    (data['purchase_number'] <= 2)\n",
    "]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>country_code</th>\n",
       "      <th>email</th>\n",
       "      <th>municipality</th>\n",
       "      <th>city</th>\n",
       "      <th>production</th>\n",
       "      <th>start_date</th>\n",
       "      <th>artform</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>is_premiere</th>\n",
       "      <th>is_flirt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>distance_to_nob</th>\n",
       "      <th>nl_spatial_imputed</th>\n",
       "      <th>median_income</th>\n",
       "      <th>domestic_median_imputed</th>\n",
       "      <th>foreign_median_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>ljjschuurmans@gmail.com</td>\n",
       "      <td>delft</td>\n",
       "      <td>delft</td>\n",
       "      <td>22/23 turandot</td>\n",
       "      <td>2022-12-12 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00667</td>\n",
       "      <td>4.35556</td>\n",
       "      <td>54.854622</td>\n",
       "      <td>0</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>ljjschuurmans@gmail.com</td>\n",
       "      <td>delft</td>\n",
       "      <td>delft</td>\n",
       "      <td>22/23 messa da requiem</td>\n",
       "      <td>2023-02-13 20:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00667</td>\n",
       "      <td>4.35556</td>\n",
       "      <td>54.854622</td>\n",
       "      <td>0</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>eskersterneberg@gmail.com</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>18/19 juditha triumphans</td>\n",
       "      <td>2019-02-01 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1991-08-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>eskersterneberg@gmail.com</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>21/22 made in amsterdam</td>\n",
       "      <td>2022-02-20 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1991-08-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>e.houtman@houthoff.com</td>\n",
       "      <td>None</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>22/23 the sleeping beauty</td>\n",
       "      <td>2022-12-27 19:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.434026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434708</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>linda.joep@casema.nl</td>\n",
       "      <td>None</td>\n",
       "      <td>houten</td>\n",
       "      <td>24/25 die fledermaus</td>\n",
       "      <td>2024-12-29 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1957-02-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.02833</td>\n",
       "      <td>5.16806</td>\n",
       "      <td>41.909596</td>\n",
       "      <td>0</td>\n",
       "      <td>48.684134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434709</th>\n",
       "      <td>2.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>f_duursema@hotmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>24/25 idomeneo</td>\n",
       "      <td>2025-02-15 19:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.434026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434710</th>\n",
       "      <td>4.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>mirna@upcmail.nl</td>\n",
       "      <td>None</td>\n",
       "      <td>weesp</td>\n",
       "      <td>24/25 die fledermaus</td>\n",
       "      <td>2024-12-10 19:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2003-10-31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.30750</td>\n",
       "      <td>5.04167</td>\n",
       "      <td>11.640816</td>\n",
       "      <td>0</td>\n",
       "      <td>34.573199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434711</th>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>jonathanebrito@gmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24/25 notenkraker en muizenkoning</td>\n",
       "      <td>2024-12-28 14:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.667152</td>\n",
       "      <td>1</td>\n",
       "      <td>69.338000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434712</th>\n",
       "      <td>3.0</td>\n",
       "      <td>nl</td>\n",
       "      <td>sgoldienl@gmail.com</td>\n",
       "      <td>None</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>24/25 jewels</td>\n",
       "      <td>2025-03-01 20:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1973-11-25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.37403</td>\n",
       "      <td>4.88969</td>\n",
       "      <td>1.095892</td>\n",
       "      <td>0</td>\n",
       "      <td>33.434026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329211 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rank country_code                      email municipality       city  \\\n",
       "0       1.0           nl    ljjschuurmans@gmail.com        delft      delft   \n",
       "1       2.0           nl    ljjschuurmans@gmail.com        delft      delft   \n",
       "2       2.0           nl  eskersterneberg@gmail.com    amsterdam  amsterdam   \n",
       "3       2.0           nl  eskersterneberg@gmail.com    amsterdam  amsterdam   \n",
       "6       4.0           nl     e.houtman@houthoff.com         None  amsterdam   \n",
       "...     ...          ...                        ...          ...        ...   \n",
       "434708  1.0           nl       linda.joep@casema.nl         None     houten   \n",
       "434709  2.0           nl     f_duursema@hotmail.com         None  amsterdam   \n",
       "434710  4.0           nl           mirna@upcmail.nl         None      weesp   \n",
       "434711  3.0         None   jonathanebrito@gmail.com         None       None   \n",
       "434712  3.0           nl        sgoldienl@gmail.com         None  amsterdam   \n",
       "\n",
       "                               production          start_date  artform  \\\n",
       "0                          22/23 turandot 2022-12-12 20:00:00        1   \n",
       "1                  22/23 messa da requiem 2023-02-13 20:15:00        1   \n",
       "2                18/19 juditha triumphans 2019-02-01 20:00:00        1   \n",
       "3                 21/22 made in amsterdam 2022-02-20 14:00:00        0   \n",
       "6               22/23 the sleeping beauty 2022-12-27 19:30:00        0   \n",
       "...                                   ...                 ...      ...   \n",
       "434708               24/25 die fledermaus 2024-12-29 14:00:00        1   \n",
       "434709                     24/25 idomeneo 2025-02-15 19:30:00        1   \n",
       "434710               24/25 die fledermaus 2024-12-10 19:30:00        1   \n",
       "434711  24/25 notenkraker en muizenkoning 2024-12-28 14:00:00        0   \n",
       "434712                       24/25 jewels 2025-03-01 20:15:00        0   \n",
       "\n",
       "         gender  birthdate  ...  gender_female is_premiere is_flirt  latitude  \\\n",
       "0       unknown 1999-03-23  ...              0           0        0  52.00667   \n",
       "1       unknown 1999-03-23  ...              0           0        0  52.00667   \n",
       "2        female 1991-08-11  ...              1           0        0  52.37403   \n",
       "3        female 1991-08-11  ...              1           1        0  52.37403   \n",
       "6       unknown        NaT  ...              0           0        0  52.37403   \n",
       "...         ...        ...  ...            ...         ...      ...       ...   \n",
       "434708   female 1957-02-06  ...              1           0        0  52.02833   \n",
       "434709  unknown        NaT  ...              0           0        0  52.37403   \n",
       "434710  unknown 2003-10-31  ...              0           0        0  52.30750   \n",
       "434711     None        NaT  ...              0           0        0       NaN   \n",
       "434712   female 1973-11-25  ...              1           0        0  52.37403   \n",
       "\n",
       "        longitude  distance_to_nob  nl_spatial_imputed  median_income  \\\n",
       "0         4.35556        54.854622                   0      29.600000   \n",
       "1         4.35556        54.854622                   0      29.600000   \n",
       "2         4.88969         1.095892                   0      33.400000   \n",
       "3         4.88969         1.095892                   0      33.400000   \n",
       "6         4.88969         1.095892                   0      33.434026   \n",
       "...           ...              ...                 ...            ...   \n",
       "434708    5.16806        41.909596                   0      48.684134   \n",
       "434709    4.88969         1.095892                   0      33.434026   \n",
       "434710    5.04167        11.640816                   0      34.573199   \n",
       "434711        NaN        24.667152                   1      69.338000   \n",
       "434712    4.88969         1.095892                   0      33.434026   \n",
       "\n",
       "        domestic_median_imputed  foreign_median_imputed  \n",
       "0                             0                       0  \n",
       "1                             0                       0  \n",
       "2                             0                       0  \n",
       "3                             0                       0  \n",
       "6                             1                       0  \n",
       "...                         ...                     ...  \n",
       "434708                        1                       0  \n",
       "434709                        1                       0  \n",
       "434710                        1                       0  \n",
       "434711                        0                       1  \n",
       "434712                        1                       0  \n",
       "\n",
       "[329211 rows x 195 columns]"
      ]
     },
     "execution_count": 1650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('id').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for training\n",
    "general_cols = ['artform','order_size','min_purchase_date', 'total_order_value', 'avg_order_value',\n",
    "                'tickets_sold', 'cumulative_sales', 'lead_days', 'next_purchase_date', 'time', 'is_nl',\n",
    "                'email_provided', 'municipality_provided', 'city_provided', 'days_since_first_purchase',\n",
    "                'distance_to_nob', 'nl_spatial_imputed', 'domestic_median_imputed', 'foreign_median_imputed',\n",
    "                'median_income', 'is_flirt','is_premiere']\n",
    "\n",
    "age_cols = ['age_under_18', 'age_18_35', 'age_36_55', 'age_over_55', 'age_unknown', 'age_other']\n",
    "\n",
    "rank_cols = [col for col in data.columns if col.startswith('ballet_rank') or col.startswith('opera_rank')]\n",
    "\n",
    "purchase_date_cols = [col for col in data.columns if col.startswith('purchase_dayofweek') or col.startswith('purchase_month')]\n",
    "start_date_cols = [col for col in data.columns if col.startswith('start_dayofweek') or col.startswith('start_month')]\n",
    "\n",
    "season_cols = [col for col in data.columns if col.startswith('season_')]\n",
    "\n",
    "ticket_type_cols = [col for col in data.columns if col.startswith('tickets_type_')]\n",
    "\n",
    "# retain only the first and second instance of a purchase (if available)\n",
    "training_data = data[data['purchase_number'] <= 2]\n",
    "\n",
    "training_data = data[general_cols + rank_cols + age_cols + purchase_date_cols + start_date_cols + season_cols + ticket_type_cols]\n",
    "\n",
    "# drop columns with only one unique value\n",
    "training_data = training_data.drop(columns=training_data.columns[training_data.nunique() == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all numerical columns to float32\n",
    "for col in training_data.select_dtypes(include='number').columns:\n",
    "    training_data[col] = training_data[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export training data as parquet\n",
    "training_data.to_parquet('../../data/processed/training_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
