{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be1009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "\n",
    "# prevents a thread conflict between MKL/OpenMP (used by numpy/scipy) and PyTorch\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAX_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae52a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sksurv.util import Surv\n",
    "import pickle\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "import torch.nn as nn\n",
    "import torchtuples as tt\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "# random seed for reproducibility\n",
    "np.random.seed(1212)\n",
    "torch.manual_seed(1212)\n",
    "\n",
    "# models\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from xgbse.converters import convert_to_structured\n",
    "from xgbse import XGBSEDebiasedBCE\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "from pycox.models import DeepHitSingle, CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "\n",
    "# metrics\n",
    "from sksurv.metrics import cumulative_dynamic_auc, concordance_index_censored, integrated_brier_score, concordance_index_ipcw\n",
    "\n",
    "\n",
    "# survshap\n",
    "from survshap import SurvivalModelExplainer, ModelSurvSHAP\n",
    "\n",
    "# warnings\n",
    "# import warnings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X_train = pd.read_parquet('../../data/processed/train_standard_features.parquet')\n",
    "y_train = pd.read_parquet('../../data/processed/train_targets.parquet')\n",
    "X_val = pd.read_parquet('../../data/processed/val_standard_features.parquet')\n",
    "y_val = pd.read_parquet('../../data/processed/val_targets.parquet')\n",
    "X_test = pd.read_parquet('../../data/processed/test_standard_features.parquet')\n",
    "y_test = pd.read_parquet('../../data/processed/test_targets.parquet')\n",
    "\n",
    "y_train_struct = np.array([(bool(e), float(t)) for e, t in zip(y_train['event'], y_train['time'])], \n",
    "                        dtype=[('event', bool), ('time', float)])\n",
    "y_val_struct = np.array([(bool(e), float(t)) for e, t in zip(y_val['event'], y_val['time'])], \n",
    "                    dtype=[('event', bool), ('time', float)])\n",
    "y_test_struct = np.array([(bool(e), float(t)) for e, t in zip(y_test['event'], y_test['time'])], \n",
    "                    dtype=[('event', bool), ('time', float)])\n",
    "\n",
    "y_train_struct_xgbse = convert_to_structured(y_train['time'], y_train['event'])\n",
    "y_val_struct_xgbse = convert_to_structured(y_val['time'], y_val['event'])\n",
    "y_test_struct_xgbse = convert_to_structured(y_test['time'], y_test['event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time = np.min(y_test_struct['time'])\n",
    "max_time = np.max(y_test_struct['time'])\n",
    "# ensure times_for_brier is within [min_time, max_time)\n",
    "times_for_brier = np.arange(np.ceil(min_time), np.floor(max_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3642ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time, max_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2b28b",
   "metadata": {},
   "source": [
    "## Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec390dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cox(trial):\n",
    "    # hyperparameter search space\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 0.001, 10.0, log=True),\n",
    "        'n_iter': trial.suggest_int('n_iter', 100, 2000),\n",
    "        'tol': trial.suggest_float('tol', 1e-6, 1e-3, log=True),\n",
    "    }\n",
    "    \n",
    "    times = np.arange(1, 361)\n",
    "    \n",
    "    try:\n",
    "        # train and evaluate model\n",
    "        model = CoxPHSurvivalAnalysis(**params)\n",
    "        model.fit(X_train, y_train_struct)\n",
    "        \n",
    "        # get predictions for both sets\n",
    "        train_risks = model.predict(X_train)\n",
    "        val_risks = model.predict(X_val)\n",
    "        \n",
    "        # calculate c-index for both\n",
    "        train_c_index = concordance_index_censored(\n",
    "            y_train_struct['event'], y_train_struct['time'], train_risks)[0]\n",
    "        val_c_index = concordance_index_censored(\n",
    "            y_val_struct['event'], y_val_struct['time'], val_risks)[0]\n",
    "        \n",
    "        # mean AUC score\n",
    "        _ , mean_auc = cumulative_dynamic_auc(\n",
    "            y_train_struct, y_val_struct, val_risks, times)\n",
    "        \n",
    "        # store metrics and coefficients\n",
    "        trial.set_user_attr('train_c_index', train_c_index)\n",
    "        trial.set_user_attr('val_c_index', val_c_index)\n",
    "        trial.set_user_attr('mean_auc', mean_auc)\n",
    "        \n",
    "        if hasattr(model, 'coef_'):\n",
    "            coef_dict = {name: float(coef) for name, coef in zip(X_train.columns, model.coef_)}\n",
    "            trial.set_user_attr('coefficients', coef_dict)\n",
    "        \n",
    "        return val_c_index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return float('-inf')\n",
    "\n",
    "# run optimization\n",
    "study_cox = optuna.create_study(direction='maximize')\n",
    "study_cox.optimize(objective_cox, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "# save results\n",
    "best_trial_cox = study_cox.best_trial\n",
    "print(f\"\\nBest score: {best_trial_cox.value:.5f}\")\n",
    "print(f\"Train c-index: {best_trial_cox.user_attrs['train_c_index']:.5f}\")\n",
    "print(f\"Val c-index: {best_trial_cox.user_attrs['val_c_index']:.5f}\")\n",
    "print(f\"Mean AUC: {best_trial_cox.user_attrs['mean_auc']:.5f}\")\n",
    "print(f\"Best params: {best_trial_cox.params}\")\n",
    "\n",
    "# save parameters\n",
    "with open('../../models/best_cox_params.json', 'w') as f:\n",
    "    json.dump(study_cox.best_params, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "# load the best hyperparameters\n",
    "with open('../../models/best_cox_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"best hyperparameters:\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# parameters for model initialization\n",
    "cox_params = {\n",
    "    'alpha': best_params['alpha'],\n",
    "    'n_iter': best_params['n_iter'],\n",
    "    'tol': best_params['tol'],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# train the final model\n",
    "print(\"training final model\")\n",
    "cox_model = CoxPHSurvivalAnalysis(**cox_params)\n",
    "\n",
    "cox_model.fit(\n",
    "    X_train, \n",
    "    y_train_struct\n",
    ")\n",
    "\n",
    "print(\"training complete\")\n",
    "\n",
    "# predictions on test set\n",
    "print(\"predictions on test\")\n",
    "cox_test_surv_probs = cox_model.predict_survival_function(X_test)\n",
    "cox_surv_funcs = cox_model.predict_survival_function(X_test, return_array=False)\n",
    "\n",
    "cox_test_surv_probs_ibs = np.vstack([fn(times_for_brier) for fn in cox_surv_funcs])\n",
    "\n",
    "cox_test_risks = cox_model.predict(X_test)\n",
    "\n",
    "\n",
    "# c index\n",
    "cox_test_c_index = concordance_index_censored(\n",
    "    y_test_struct['event'], \n",
    "    y_test_struct['time'], \n",
    "    cox_test_risks\n",
    ")[0]\n",
    "\n",
    "# cumulative dynamic AUC\n",
    "cox_td_auc, cox_test_mean_auc = cumulative_dynamic_auc(\n",
    "    y_train_struct, y_test_struct, cox_test_risks, times=list(range(1, 361))\n",
    ")\n",
    "\n",
    "# ibs\n",
    "cox_ibs_score = integrated_brier_score(\n",
    "        survival_train=y_test_struct, # use test set censoring distribution like pycox\n",
    "        survival_test=y_test_struct,\n",
    "        estimate=cox_test_surv_probs_ibs,\n",
    "        times=times_for_brier\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"\\nFINAL TEST RESULTS\")\n",
    "print(f\"test C-index: {cox_test_c_index:.5f}\")\n",
    "print(f\"test mean AUC: {cox_test_mean_auc:.5f}\")\n",
    "print(f\"IBS: {cox_ibs_score:.4f}\")\n",
    "\n",
    "# save the final model\n",
    "print(\"saving final model\")\n",
    "import pickle\n",
    "with open('../../models/final_cox_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cox_model, f)\n",
    "\n",
    "# save test predictions\n",
    "cox_test_predictions = {\n",
    "    'survival_probabilities': cox_test_surv_probs,\n",
    "    'risk_scores': cox_test_risks,\n",
    "    'c_index': cox_test_c_index,\n",
    "    'mean_auc': cox_test_mean_auc,\n",
    "    'ibs': cox_ibs_score\n",
    "}\n",
    "\n",
    "with open('../../models/cox_test_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(cox_test_predictions, f)\n",
    "\n",
    "print('model and predictions saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617b0f7",
   "metadata": {},
   "source": [
    "## Random Survival Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rsf(trial):\n",
    "    # hyperparameter search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 80, 200),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 10, 30), \n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 20), \n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'max_samples': trial.suggest_float('max_samples', 0.6, 0.9),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 1212\n",
    "    }\n",
    "    \n",
    "    times = np.arange(1, 361)\n",
    "    \n",
    "    try:\n",
    "        # train and evaluate model\n",
    "        model = RandomSurvivalForest(**params)\n",
    "        model.fit(X_train, y_train_struct)\n",
    "        \n",
    "        # predictions for both sets\n",
    "        train_risks = model.predict(X_train)\n",
    "        val_risks = model.predict(X_val)\n",
    "        \n",
    "        # c-index for both\n",
    "        train_c_index = concordance_index_censored(\n",
    "            y_train_struct['event'], y_train_struct['time'], train_risks)[0]\n",
    "        val_c_index = concordance_index_censored(\n",
    "            y_val_struct['event'], y_val_struct['time'], val_risks)[0]\n",
    "        \n",
    "        # mean AUC score\n",
    "        _, mean_auc = cumulative_dynamic_auc(\n",
    "            y_train_struct, y_val_struct, val_risks, times)\n",
    "        \n",
    "        # store metrics\n",
    "        trial.set_user_attr('train_c_index', train_c_index)\n",
    "        trial.set_user_attr('val_c_index', val_c_index)\n",
    "        trial.set_user_attr('mean_auc', mean_auc)\n",
    "        \n",
    "        return val_c_index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return float('-inf')\n",
    "\n",
    "# run optimization for the RSF model\n",
    "study_rsf = optuna.create_study(direction='maximize')\n",
    "study_rsf.optimize(objective_rsf, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "# save results\n",
    "print(\"\\nRSF best trial\")\n",
    "# assign the best trial from the correct study\n",
    "best_trial_rsf = study_rsf.best_trial\n",
    "\n",
    "# print 'best_trial_rsf' metrics\n",
    "print(f\"best score: {best_trial_rsf.value:.5f}\")\n",
    "print(f\"train C-index: {best_trial_rsf.user_attrs['train_c_index']:.5f}\")\n",
    "print(f\"val C-index: {best_trial_rsf.user_attrs['val_c_index']:.5f}\")\n",
    "print(f\"mean AUC: {best_trial_rsf.user_attrs['mean_auc']:.5f}\")\n",
    "print(f\"best params: {best_trial_rsf.params}\")\n",
    "\n",
    "# save parameters \n",
    "with open('../../models/best_rsf_params.json', 'w') as f:\n",
    "    json.dump(study_rsf.best_params, f, indent=2)\n",
    "\n",
    "print(\"model and predictions saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb898c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "# load the best hyperparameters\n",
    "with open('../../models/best_rsf_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"best hyperparameters:\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# parameters for model initialization\n",
    "rsf_params = {\n",
    "    'n_estimators': best_params['n_estimators'],\n",
    "    'min_samples_split': best_params['min_samples_split'],\n",
    "    'min_samples_leaf': best_params['min_samples_leaf'],\n",
    "    'max_depth': best_params['max_depth'],\n",
    "    'max_samples': best_params['max_samples'],\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 1212\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# train the final model\n",
    "print(\"training final model\")\n",
    "rsf_model = RandomSurvivalForest(**rsf_params)\n",
    "\n",
    "rsf_model.fit(\n",
    "    X_train, \n",
    "    y_train_struct\n",
    ")\n",
    "\n",
    "print(\"model training complete\")\n",
    "\n",
    "# predict on test set\n",
    "print(\"predictions on test\")\n",
    "rsf_test_surv_probs = rsf_model.predict_survival_function(X_test)\n",
    "rsf_surv_funcs = rsf_model.predict_survival_function(X_test, return_array=False)\n",
    "\n",
    "rsf_test_surv_probs_ibs = np.vstack([fn(times_for_brier) for fn in rsf_surv_funcs])\n",
    "\n",
    "rsf_test_risks = rsf_model.predict(X_test)\n",
    "\n",
    "\n",
    "# c index\n",
    "rsf_test_c_index = concordance_index_censored(\n",
    "    y_test_struct['event'], \n",
    "    y_test_struct['time'], \n",
    "    rsf_test_risks\n",
    ")[0]\n",
    "\n",
    "# cumulative dynamic AUC\n",
    "rsf_td_auc, rsf_test_mean_auc = cumulative_dynamic_auc(\n",
    "    y_train_struct, y_test_struct, rsf_test_risks, times=list(range(1, 361))\n",
    ")\n",
    "\n",
    "# ibs\n",
    "rsf_ibs_score = integrated_brier_score(\n",
    "        survival_train=y_test_struct, \n",
    "        survival_test=y_test_struct,\n",
    "        estimate=rsf_test_surv_probs_ibs,\n",
    "        times=times_for_brier\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"\\nFINAL TEST RESULTS\")\n",
    "print(f\"test C-index: {rsf_test_c_index:.5f}\")\n",
    "print(f\"test mean AUC: {rsf_test_mean_auc:.5f}\")\n",
    "print(f\"IBS: {rsf_ibs_score:.4f}\")\n",
    "\n",
    "# save the final model\n",
    "print(\"saving final model\")\n",
    "import pickle\n",
    "with open('../../models/final_rsf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rsf_model, f)\n",
    "\n",
    "# save test predictions\n",
    "rsf_test_predictions = {\n",
    "    'survival_probabilities': rsf_test_surv_probs,\n",
    "    'risk_scores': rsf_test_risks,\n",
    "    'c_index': rsf_test_c_index,\n",
    "    'mean_auc': rsf_test_mean_auc,\n",
    "    'ibs': rsf_ibs_score\n",
    "}\n",
    "\n",
    "with open('../../models/rsf_test_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(rsf_test_predictions, f)\n",
    "\n",
    "print(\"model and predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e9404",
   "metadata": {},
   "source": [
    "## XGBSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4778f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter search\n",
    "def get_risk_scores(survival_probs):\n",
    "    \"\"\"convert survival probabilities to risk scores for c-index calculation\"\"\"\n",
    "    return 1 - survival_probs.mean(axis=1)\n",
    "\n",
    "def objective_xgbse(trial):\n",
    "    # XGBoost hyperparameters\n",
    "    xgb_params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 2), \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'random_state': 1212\n",
    "    }\n",
    "    \n",
    "    # BCE specific hyperparameters\n",
    "    lr_params = {\n",
    "        'C': trial.suggest_float('lr_C', 0.001, 100, log=True),\n",
    "        'max_iter': trial.suggest_int('lr_max_iter', 100, 1000)\n",
    "    }\n",
    "    \n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 50, 300)\n",
    "\n",
    "    times = np.arange(0, 361, 30).tolist()\n",
    "    \n",
    "    try:\n",
    "        model = XGBSEDebiasedBCE(\n",
    "            xgb_params=xgb_params,\n",
    "            lr_params=lr_params,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train, \n",
    "            y_train_struct, \n",
    "            time_bins=times, \n",
    "            num_boost_round=num_boost_round)\n",
    "        \n",
    "        # survival probabilities and convert to risk scores\n",
    "        train_survival_probs = model.predict(X_train)\n",
    "        val_survival_probs = model.predict(X_val)\n",
    "        \n",
    "        train_risks = get_risk_scores(train_survival_probs)\n",
    "        val_risks = get_risk_scores(val_survival_probs)\n",
    "        \n",
    "        # c-index\n",
    "        train_c_index = concordance_index_censored(\n",
    "            y_train_struct['event'], y_train_struct['time'], train_risks)[0]\n",
    "        val_c_index = concordance_index_censored(\n",
    "            y_val_struct['event'], y_val_struct['time'], val_risks)[0]\n",
    "        \n",
    "        # mean AUC\n",
    "        _, mean_auc = cumulative_dynamic_auc(\n",
    "            y_train_struct, y_val_struct, val_risks, times=list(range(1, 361)))\n",
    "        \n",
    "        # store metrics\n",
    "        trial.set_user_attr('train_c_index', train_c_index)\n",
    "        trial.set_user_attr('val_c_index', val_c_index)\n",
    "        trial.set_user_attr('mean_auc', mean_auc)\n",
    "        \n",
    "        return val_c_index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return float('-inf')\n",
    "    \n",
    "# run optimization\n",
    "study_xgbse = optuna.create_study(direction='maximize')\n",
    "study_xgbse.optimize(objective_xgbse, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "# save results\n",
    "best_trial_xgbse = study_xgbse.best_trial\n",
    "print(f\"\\nBest score: {best_trial_xgbse.value:.5f}\")\n",
    "print(f\"Train c-index: {best_trial_xgbse.user_attrs['train_c_index']:.5f}\")\n",
    "print(f\"Val c-index: {best_trial_xgbse.user_attrs['val_c_index']:.5f}\")\n",
    "print(f\"Mean AUC: {best_trial_xgbse.user_attrs['mean_auc']:.5f}\")\n",
    "print(f\"Best params: {best_trial_xgbse.params}\")\n",
    "\n",
    "# save parameters\n",
    "with open('../../models/best_xgbse_params.json', 'w') as f:\n",
    "    json.dump(study_xgbse.best_params, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def calculate_ibs_for_xgbse(model, X_train, y_train_struct, X_test, y_test_struct):\n",
    "    min_time = np.min(y_test_struct['time'])\n",
    "    max_time = np.max(y_test_struct['time'])\n",
    "    # times_for_brier is within [min_time, max_time)\n",
    "    times_for_brier = np.arange(np.ceil(min_time), np.floor(max_time))\n",
    "    \n",
    "\n",
    "    xgbse_pred_df = model.predict(X_test)\n",
    "    \n",
    "    # get the time bins from the model\n",
    "    xgbse_time_bins = model.time_bins\n",
    "    \n",
    "    # interpolate predictions onto new time grid\n",
    "    interpolated_probs = np.zeros((X_test.shape[0], len(times_for_brier)))\n",
    "    \n",
    "    for i in range(len(xgbse_pred_df)):\n",
    "        # get survival probabilities for i-th patient\n",
    "        patient_probs = xgbse_pred_df.iloc[i].values\n",
    "        \n",
    "        # Interpolate to new time grid\n",
    "        interpolated_probs[i, :] = np.interp(\n",
    "            x=times_for_brier,      # new time points\n",
    "            xp=xgbse_time_bins,     # XGBSE time bins\n",
    "            fp=patient_probs,       \n",
    "            left=1.0,               # surv prob is 1 before first time bin\n",
    "            right=patient_probs[-1] # extend last value after last time bin\n",
    "        )\n",
    "    \n",
    "    # Step 5: Calculate IBS using scikit-survival\n",
    "    xgbse_ibs_score = integrated_brier_score(\n",
    "        survival_train=y_test_struct, # use test set censoring distribution like pycox\n",
    "        survival_test=y_test_struct,\n",
    "        estimate=interpolated_probs,\n",
    "        times=times_for_brier\n",
    "    )\n",
    "    \n",
    "    return xgbse_ibs_score\n",
    "\n",
    "# load the best hyperparameters\n",
    "with open('../../models/best_xgbse_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"best hyperparameters:\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# extract parameters for model initialization\n",
    "xgb_params = {\n",
    "    'max_depth': best_params['max_depth'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'reg_alpha': best_params['reg_alpha'],\n",
    "    'min_child_weight': best_params['min_child_weight'],\n",
    "    'random_state': 1212\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'C': best_params['lr_C'],\n",
    "    'max_iter': best_params['lr_max_iter']\n",
    "}\n",
    "\n",
    "num_boost_round = best_params['num_boost_round']\n",
    "\n",
    "# time bins\n",
    "times_xgbse = np.arange(0, 361, 30).tolist()\n",
    "print(f\"Time bins: {times_xgbse}\")\n",
    "\n",
    "\n",
    "# train the final model\n",
    "print(\"training final model\")\n",
    "xgbse_model = XGBSEDebiasedBCE(\n",
    "    xgb_params=xgb_params,\n",
    "    lr_params=lr_params,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgbse_model.fit(\n",
    "    X_train, \n",
    "    y_train_struct, \n",
    "    time_bins=times_xgbse, \n",
    "    num_boost_round=num_boost_round\n",
    ")\n",
    "\n",
    "print(\"model training complete\")\n",
    "\n",
    "# predict on test set\n",
    "print(\"predictions on test\")\n",
    "xgbse_test_survival_probs = xgbse_model.predict(X_test)\n",
    "xgbse_test_risks = get_risk_scores(xgbse_test_survival_probs)\n",
    "\n",
    "\n",
    "# C index\n",
    "xgbse_test_c_index = concordance_index_censored(\n",
    "    y_test_struct['event'], \n",
    "    y_test_struct['time'], \n",
    "    xgbse_test_risks\n",
    ")[0]\n",
    "\n",
    "# cumulative dynamic AUC\n",
    "xgbse_td_auc, xgbse_test_mean_auc = cumulative_dynamic_auc(\n",
    "    y_train_struct, y_test_struct, xgbse_test_risks, times=list(range(1, 361))\n",
    ")\n",
    "\n",
    "# ibs\n",
    "xgbse_ibs_score = calculate_ibs_for_xgbse(\n",
    "    xgbse_model, \n",
    "    X_train, \n",
    "    y_train_struct, \n",
    "    X_test, \n",
    "    y_test_struct\n",
    "    )\n",
    "\n",
    "print(f\"\\nFINAL TEST RESULTS\")\n",
    "print(f\"Test C-index: {xgbse_test_c_index:.5f}\")\n",
    "print(f\"Test Mean AUC: {xgbse_test_mean_auc:.5f}\")\n",
    "print(f\"IBS: {xgbse_ibs_score:.4f}\")\n",
    "\n",
    "# save the final model\n",
    "print(\"Saving final model...\")\n",
    "import pickle\n",
    "with open('../../models/final_xgbse_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgbse_model, f)\n",
    "\n",
    "# save test predictions\n",
    "xgbse_test_predictions = {\n",
    "    'survival_probabilities': xgbse_test_survival_probs,\n",
    "    'risk_scores': xgbse_test_risks,\n",
    "    'c_index': xgbse_test_c_index,\n",
    "    'mean_auc': xgbse_test_mean_auc,\n",
    "    'time_bins': times_xgbse\n",
    "}\n",
    "\n",
    "with open('../../models/xgbse_test_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(xgbse_test_predictions, f)\n",
    "\n",
    "print(\"model and predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f68ea",
   "metadata": {},
   "source": [
    "## DeepHit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llms were useful for making this work\n",
    "\n",
    "def get_risk_scores_repurchase_expected_time(model, X):\n",
    "    # get the predicted survival probs as df\n",
    "    # rows=individuals, cols=time points\n",
    "    surv_probs_df = model.predict_surv_df(X)\n",
    "    \n",
    "    # transposition logic as safeguard\n",
    "    if surv_probs_df.shape[0] < surv_probs_df.shape[1]:\n",
    "        surv_probs_df = surv_probs_df.T\n",
    "    \n",
    "    # get time points and calculate the width of each time interval\n",
    "    time_points = surv_probs_df.columns.values\n",
    "    \n",
    "    # prepend t=0 to the time points to correctly calculate the first interval's width (t_1 - 0)\n",
    "    time_points_with_zero = np.insert(time_points, 0, 0)\n",
    "    \n",
    "    # time_diffs will be an array of interval durations: [t_1-0, t_2-t_1, t_3-t_2, ...]\n",
    "    time_diffs = np.diff(time_points_with_zero)\n",
    "    \n",
    "    # calculate the expected survival time as the area under the curve\n",
    "    # the sum of S(t_i) * (t_i - t_{i-1}) for each interval\n",
    "    # calculate using dot product\n",
    "    surv_probs_np = surv_probs_df.values\n",
    "    expected_times = np.dot(surv_probs_np, time_diffs)\n",
    "    \n",
    "    # return the NEGATIVE expected time.\n",
    "    return -expected_times\n",
    "\n",
    "# time discretization\n",
    "cuts = np.arange(0, 361, 30, dtype=np.float32)\n",
    "labtrans = LabTransDiscreteTime(cuts=cuts)\n",
    "y_train_transformed = labtrans.fit_transform(y_train['time'], y_train['event'])\n",
    "# y_val_transformed = labtrans.transform(y_val['time'], y_val['event'])\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "def objective_deephit(trial):\n",
    "    # hyperparameter ranges\n",
    "    batch_norm = trial.suggest_categorical('batch_norm', [True, False])\n",
    "    dropout_prob = trial.suggest_float('dropout_prob', 0.1, 0.3)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 3)\n",
    "    num_nodes = trial.suggest_categorical('num_nodes', [32, 64, 128])\n",
    "    output_bias = trial.suggest_categorical('output_bias', [True, False])\n",
    "    reg = trial.suggest_float('reg', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    times = list(range(1, 361))\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        \n",
    "        print(f\"data shapes: X_train={X_train.shape}, y_train_transformed={y_train_transformed[0].shape if isinstance(y_train_transformed, tuple) else len(y_train_transformed)}\")\n",
    "        print(f\"labtrans cuts: {len(labtrans.cuts)}, out_features: {labtrans.out_features}\")\n",
    "        \n",
    "        # build network\n",
    "        layers = []\n",
    "        current_size = X_train.shape[1]\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(current_size, num_nodes))\n",
    "            layers.append(nn.ReLU())\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(num_nodes))\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "            current_size = num_nodes\n",
    "            \n",
    "        layers.append(nn.Linear(current_size, labtrans.out_features, bias=output_bias))\n",
    "        net = nn.Sequential(*layers).to(DEVICE)\n",
    "        \n",
    "        # model setup\n",
    "        optimizer = AdamW(net.parameters(), lr=lr, weight_decay=reg)\n",
    "        model = DeepHitSingle(net, optimizer, alpha=0.2, sigma=0.1,\n",
    "                              duration_index=labtrans.cuts, device=DEVICE)\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"starting model training\")\n",
    "        # train model\n",
    "        model.fit(X_train.values, y_train_transformed, \n",
    "                  batch_size=256, epochs=30, verbose=False)\n",
    "        \n",
    "        print(\"model training complete, calculating predictions\")\n",
    "        # debug the prediction step\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(DEVICE)\n",
    "        X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(DEVICE)\n",
    "        \n",
    "        print(f\"input tensor shapes: X_train={X_train_tensor.shape}, X_val={X_val_tensor.shape}\")\n",
    "        \n",
    "        # get risk scores and calculate metrics\n",
    "        train_risks = get_risk_scores_repurchase_expected_time(model, X_train_tensor)\n",
    "        val_risks = get_risk_scores_repurchase_expected_time(model, X_val_tensor)\n",
    "        \n",
    "        print(\"risk scores calculated\")\n",
    "        \n",
    "        train_c_index = concordance_index_censored(y_train_struct['event'], y_train_struct['time'], train_risks)[0]\n",
    "        val_c_index = concordance_index_censored(y_val_struct['event'], y_val_struct['time'], val_risks)[0]\n",
    "        _, mean_auc = cumulative_dynamic_auc(y_train_struct, y_val_struct, val_risks, times)\n",
    "        \n",
    "        trial.set_user_attr('train_c_index', train_c_index)\n",
    "        trial.set_user_attr('val_c_index', val_c_index)\n",
    "        trial.set_user_attr('mean_auc', mean_auc)\n",
    "        \n",
    "        return val_c_index\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"trial failed with full traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "        return float('-inf')\n",
    "\n",
    "# optimization\n",
    "study_deephit = optuna.create_study(direction='maximize')\n",
    "study_deephit.optimize(objective_deephit, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "# save results\n",
    "if study_deephit.best_trial.value != float('-inf'):\n",
    "    best_trial_deephit = study_deephit.best_trial\n",
    "    print(f\"\\nBest score: {best_trial_deephit.value:.5f}\")\n",
    "    print(f\"Train c-index: {best_trial_deephit.user_attrs['train_c_index']:.5f}\")\n",
    "    print(f\"Val c-index: {best_trial_deephit.user_attrs['val_c_index']:.5f}\")\n",
    "    print(f\"Mean AUC: {best_trial_deephit.user_attrs['mean_auc']:.5f}\")\n",
    "    print(f\"Best params: {best_trial_deephit.params}\")\n",
    "    \n",
    "    # save parameters\n",
    "    import json\n",
    "    with open('../../models/best_deephit_params.json', 'w') as f:\n",
    "        json.dump(study_deephit.best_params, f, indent=2)\n",
    "else:\n",
    "    print(\"all trials failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ae35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_scores_from_surv_df(surv_probs_df):\n",
    "\n",
    "    # get time points and calculate the width of each time interval\n",
    "    time_points = surv_probs_df.columns.values\n",
    "    \n",
    "    # add t=0 to the time points to calculate the first interval's width (t_1 - 0)\n",
    "    time_points_with_zero = np.insert(time_points, 0, 0)\n",
    "    \n",
    "    # time_diffs will be an array of interval durations: [t_1-0, t_2-t_1, t_3-t_2, ...]\n",
    "    time_diffs = np.diff(time_points_with_zero)\n",
    "    \n",
    "    # calculate the expected survival time as the area under the curve\n",
    "    surv_probs_np = surv_probs_df.values\n",
    "    expected_times = np.dot(surv_probs_np, time_diffs)\n",
    "    \n",
    "    # return the NEGATIVE expected time.\n",
    "    return -expected_times\n",
    "\n",
    "\n",
    "# load the best hyperparameters\n",
    "with open('../../models/best_deephit_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"best hyperparameters:\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# time discretization , use same as training\n",
    "cuts = np.arange(0, 361, 10, dtype=np.float32)\n",
    "labtrans = LabTransDiscreteTime(cuts=cuts)\n",
    "y_train_transformed = labtrans.fit_transform(y_train['time'], y_train['event'])\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "# build network\n",
    "layers = []\n",
    "current_size = X_train.shape[1]\n",
    "\n",
    "for i in range(best_params['num_layers']):\n",
    "    layers.append(nn.Linear(current_size, best_params['num_nodes']))\n",
    "    layers.append(nn.ReLU())\n",
    "    if best_params['batch_norm']:\n",
    "        layers.append(nn.BatchNorm1d(best_params['num_nodes']))\n",
    "    layers.append(nn.Dropout(best_params['dropout_prob']))\n",
    "    current_size = best_params['num_nodes']\n",
    "\n",
    "layers.append(nn.Linear(current_size, labtrans.out_features, bias=best_params['output_bias']))\n",
    "net = nn.Sequential(*layers).to(DEVICE)\n",
    "\n",
    "# initialize\n",
    "optimizer = AdamW(net.parameters(), lr=best_params['lr'], weight_decay=best_params['reg'])\n",
    "deephit_model = DeepHitSingle(net, optimizer, alpha=0.2, sigma=0.1,\n",
    "                              duration_index=labtrans.cuts, device=DEVICE)\n",
    "\n",
    "# train final model\n",
    "print(\"training final model\")\n",
    "deephit_model.fit(X_train.values, y_train_transformed, \n",
    "                  batch_size=256, epochs=30, verbose=False)\n",
    "\n",
    "print(\"model training complete\")\n",
    "\n",
    "\n",
    "# set model to evaluation mode (necessary i think)\n",
    "deephit_model.net.eval()\n",
    "\n",
    "print(\"making predictions on test\")\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# llms helped create these steps\n",
    "# STEP 1: PREDICT ONLY ONCE\n",
    "# use `predict_surv` which returns a tensor/numpy array, this is the main computation\n",
    "with torch.no_grad():\n",
    "    surv_array = deephit_model.predict_surv(X_test_tensor)\n",
    "\n",
    "# STEP 2: FIX DATAFRAME CREATION (NO .T)\n",
    "# df for calculating IBS and for saving.\n",
    "deephit_test_surv_df = pd.DataFrame(\n",
    "    surv_array, \n",
    "    columns=deephit_model.duration_index\n",
    ")\n",
    "print(f\"predictions generated, shape: {deephit_test_surv_df.shape}\")\n",
    "\n",
    "# STEP 3: CALCULATE METRICS\n",
    "\n",
    "# risk scores using existing df\n",
    "print(\"calculating risk scores\")\n",
    "deephit_test_risks = get_risk_scores_from_surv_df(deephit_test_surv_df)\n",
    "\n",
    "# c-index\n",
    "print(\"calculating C-index\")\n",
    "deephit_test_c_index = concordance_index_censored(\n",
    "    y_test_struct['event'], \n",
    "    y_test_struct['time'], \n",
    "    deephit_test_risks\n",
    ")[0]\n",
    "\n",
    "# cumulative dynamic AUC\n",
    "print(\"calculating AUC\")\n",
    "deephit_td_auc, deephit_test_mean_auc = cumulative_dynamic_auc(\n",
    "    y_train_struct, y_test_struct, deephit_test_risks, times=list(range(1, 361))\n",
    ")\n",
    "\n",
    "# interpolate survival probabilities at the required times\n",
    "surv_probs_for_sksurv = np.empty((deephit_test_surv_df.shape[0], len(times_for_brier)), dtype=np.float32)\n",
    "for i, row in enumerate(deephit_test_surv_df.values):\n",
    "    surv_probs_for_sksurv[i, :] = np.interp(\n",
    "        times_for_brier, \n",
    "        deephit_test_surv_df.columns.values, \n",
    "        row\n",
    "    )\n",
    "\n",
    "# ibs\n",
    "deephit_ibs_score = integrated_brier_score(\n",
    "    y_test_struct,           # for censoring model\n",
    "    y_test_struct,            \n",
    "    surv_probs_for_sksurv,    # prediction spare\n",
    "    times_for_brier          # time points for those predictions\n",
    ")\n",
    "\n",
    "\n",
    "# this part should now be reached without crashing due to llms figuring out the threading issue\n",
    "print(f\"\\nFINAL TEST RESULTS\")\n",
    "print(f\"etst C-index: {deephit_test_c_index:.5f}\")\n",
    "print(f\"test mean AUC: {deephit_test_mean_auc:.5f}\")\n",
    "print(f\"IBS: {deephit_ibs_score:.4f}\")\n",
    "\n",
    "# save final model\n",
    "print(\"saving final model\")\n",
    "deephit_model.save_net('../../models/final_deephit_model.pt')\n",
    "\n",
    "# save test predictions\n",
    "deephit_test_predictions = {\n",
    "    'survival_probabilities': deephit_test_surv_df,\n",
    "    'risk_scores': deephit_test_risks,\n",
    "    'c_index': deephit_test_c_index,\n",
    "    'mean_auc': deephit_test_mean_auc,\n",
    "    'time_bins': cuts[:-1].tolist()\n",
    "}\n",
    "\n",
    "with open('../../models/deephit_test_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(deephit_test_predictions, f)\n",
    "\n",
    "print(\"model and predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfa37d",
   "metadata": {},
   "source": [
    "## Deepsurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter search\n",
    "y_train_tuple = (y_train['time'].values, y_train['event'].values)\n",
    "y_val_tuple = (y_val['time'].values, y_val['event'].values)\n",
    "\n",
    "\n",
    "def objective_deepsurv(trial):\n",
    "    # hyperparameter search space\n",
    "    batch_norm = trial.suggest_categorical('batch_norm', [True, False])\n",
    "    dropout_prob = trial.suggest_float('dropout_prob', 0.1, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 4)\n",
    "    num_nodes = trial.suggest_categorical('num_nodes', [32, 64, 128])\n",
    "    output_bias = trial.suggest_categorical('output_bias', [True, False])\n",
    "    reg = trial.suggest_float('reg', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    try:\n",
    "        # build network\n",
    "        layers = []\n",
    "        current_size = X_train.shape[1]\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(current_size, num_nodes))\n",
    "            layers.append(nn.ReLU())\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(num_nodes))\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "            current_size = num_nodes\n",
    "            \n",
    "        # output layer must have 1 node for the single risk score\n",
    "        layers.append(nn.Linear(current_size, 1, bias=output_bias))\n",
    "        net = nn.Sequential(*layers).to(DEVICE)\n",
    "        \n",
    "        # model setup\n",
    "        optimizer = AdamW(net.parameters(), lr=lr, weight_decay=reg)\n",
    "        model = CoxPH(net, optimizer, device=DEVICE)\n",
    "        \n",
    "        print(\"start coxph model training\")\n",
    "        # number of epochs is fixed\n",
    "        model.fit(\n",
    "            X_train.values,\n",
    "            y_train_tuple,\n",
    "            batch_size=256,\n",
    "            epochs=30,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        print(\"training complete, calculating predictions\")\n",
    "        \n",
    "        # risk scores\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(DEVICE)\n",
    "        X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(DEVICE)\n",
    "        \n",
    "        # .predict() returns the risk scores directly\n",
    "        train_risks = model.predict(X_train_tensor).squeeze()\n",
    "        val_risks = model.predict(X_val_tensor).squeeze()\n",
    "        \n",
    "        print(\"risk scores calculated\")\n",
    "        \n",
    "        # c index train\n",
    "        train_c_index = concordance_index_censored(\n",
    "            y_train_struct['event'],\n",
    "            y_train_struct['time'], \n",
    "            train_risks)[0]\n",
    "        \n",
    "        # c index val\n",
    "        val_c_index = concordance_index_censored(\n",
    "            y_val_struct['event'], \n",
    "            y_val_struct['time'], \n",
    "            val_risks)[0]\n",
    "        \n",
    "        times = np.arange(int(y_train['time'].min()), 361, 1)\n",
    "        _, mean_auc = cumulative_dynamic_auc(y_train_struct, y_val_struct, val_risks, times)\n",
    "        \n",
    "        # store trial results\n",
    "        trial.set_user_attr('train_c_index', train_c_index)\n",
    "        trial.set_user_attr('val_c_index', val_c_index)\n",
    "        trial.set_user_attr('mean_auc', mean_auc)\n",
    "        \n",
    "        return val_c_index\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"trial failed with full traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "        return float('-inf')\n",
    "\n",
    "# run the Optuna Study\n",
    "study_deepsurv = optuna.create_study(direction='maximize')\n",
    "study_deepsurv.optimize(objective_deepsurv, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "# print and save best results\n",
    "if study_deepsurv.best_trial.value > float('-inf'):\n",
    "    best_trial_deepsurv = study_deepsurv.best_trial\n",
    "    print(\"\\ndeepSurv best trial\")\n",
    "    print(f\"best score (val C-index): {best_trial_deepsurv.value:.5f}\")\n",
    "    print(f\"train C-index: {best_trial_deepsurv.user_attrs['train_c_index']:.5f}\")\n",
    "    print(f\"mean val AUC: {best_trial_deepsurv.user_attrs['mean_auc']:.5f}\")\n",
    "    print(f\"best params: {best_trial_deepsurv.params}\")\n",
    "    \n",
    "    import json\n",
    "    with open('../../models/best_deepsurv_params.json', 'w') as f:\n",
    "        json.dump(best_trial_deepsurv.params, f, indent=2)\n",
    "else:\n",
    "    print(\"all trials failed for deepsurv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "with open('../../models/best_deepsurv_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"best deepsurv hyperparameters:\")\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "# build network\n",
    "layers = []\n",
    "current_size = X_train.shape[1]\n",
    "\n",
    "for i in range(best_params['num_layers']):\n",
    "    layers.append(nn.Linear(current_size, best_params['num_nodes']))\n",
    "    layers.append(nn.ReLU())\n",
    "    if best_params['batch_norm']:\n",
    "        layers.append(nn.BatchNorm1d(best_params['num_nodes']))\n",
    "    layers.append(nn.Dropout(best_params['dropout_prob']))\n",
    "    current_size = best_params['num_nodes']\n",
    "\n",
    "# output layer for CoxPH must have 1 node for the risk score\n",
    "layers.append(nn.Linear(current_size, 1, bias=best_params['output_bias']))\n",
    "net = nn.Sequential(*layers).to(DEVICE)\n",
    "\n",
    "# initialize model\n",
    "optimizer = AdamW(net.parameters(), lr=best_params['lr'], weight_decay=best_params['reg'])\n",
    "deepsurv_model = CoxPH(net, optimizer, device=DEVICE)\n",
    "\n",
    "# --- 2. TRAIN THE FINAL MODEL ON TRAINING DATA ---\n",
    "\n",
    "print(\"training final model\")\n",
    "# use a tuple for pycox model fitting\n",
    "y_train_tuple = (y_train['time'].values, y_train['event'].values)\n",
    "deepsurv_model.fit(X_train.values, y_train_tuple, \n",
    "                   batch_size=256, epochs=30, verbose=False)\n",
    "\n",
    "print(\"model training complete\")\n",
    "\n",
    "# MAKE PREDICTIONS\n",
    "\n",
    "deepsurv_model.net.eval()\n",
    "print(\"predictions on test set\")\n",
    "\n",
    "#  must compute the baseline hazard function on train data\n",
    "deepsurv_model.compute_baseline_hazards(X_train.values, y_train_tuple)\n",
    "\n",
    "# prepare test data tensor\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# get risk scores for c index and AUC\n",
    "deepsurv_test_risks = deepsurv_model.predict(X_test_tensor).squeeze()\n",
    "\n",
    "# get full survival probs for IBS\n",
    "deepsurv_test_surv_df = deepsurv_model.predict_surv_df(X_test_tensor)\n",
    "\n",
    "print(\"predictions generated\")\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "# time points for evaluation\n",
    "\n",
    "print(\"calculating C-index\")\n",
    "deepsurv_test_c_index = concordance_index_censored(\n",
    "    y_test_struct['event'], \n",
    "    y_test_struct['time'], \n",
    "    deepsurv_test_risks\n",
    ")[0]\n",
    "\n",
    "print(\"calculating AUC\")\n",
    "deepsurv_td_auc, deepsurv_test_mean_auc = cumulative_dynamic_auc(\n",
    "    y_train_struct, y_test_struct, deepsurv_test_risks, times=list(range(1, 361))\n",
    ")\n",
    "\n",
    "print(\"calculating IBS\")\n",
    "\n",
    "\n",
    "# predict_surv_df returns shape (n_samples, n_times) \n",
    "deepsurv_test_surv_df = deepsurv_model.predict_surv_df(X_test_tensor)\n",
    "\n",
    "# interpolate survival probabilities at the exact times needed\n",
    "n_samples = len(X_test)\n",
    "surv_probs_for_ibs = np.zeros((n_samples, len(times_for_brier)))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # get survival function for sample i ( columns are samples, rows are times)\n",
    "    surv_func = deepsurv_test_surv_df.iloc[:, i]\n",
    "    # interpolate at required times\n",
    "    surv_probs_for_ibs[i, :] = np.interp(\n",
    "        times_for_brier,\n",
    "        surv_func.index,\n",
    "        surv_func.values,\n",
    "        left=1.0,\n",
    "        right=surv_func.values[-1]\n",
    "    )\n",
    "\n",
    "# IBS\n",
    "deepsurv_ibs_score = integrated_brier_score(\n",
    "    survival_train=y_test_struct,\n",
    "    survival_test=y_test_struct,\n",
    "    estimate=surv_probs_for_ibs,\n",
    "    times=times_for_brier\n",
    ")\n",
    "\n",
    "print(f\"\\nFINAL DEEPSURV TEST RESULTS\")\n",
    "print(f\"test C-index: {deepsurv_test_c_index:.5f}\")\n",
    "print(f\"test mean AUC: {deepsurv_test_mean_auc:.5f}\")\n",
    "print(f\"IBS: {deepsurv_ibs_score:.4f}\")\n",
    "\n",
    "# SAVING\n",
    "print(\"saving final model and predictions\")\n",
    "deepsurv_model.save_net('../../models/final_deepsurv_model.pt')\n",
    "\n",
    "deepsurv_test_predictions = {\n",
    "    'survival_probabilities': deepsurv_test_surv_df,\n",
    "    'risk_scores': deepsurv_test_risks,\n",
    "    'c_index': deepsurv_test_c_index,\n",
    "    'mean_auc': deepsurv_test_mean_auc,\n",
    "    'ibs': deepsurv_ibs_score\n",
    "}\n",
    "with open('../../models/deepsurv_test_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(deepsurv_test_predictions, f)\n",
    "\n",
    "print(\"omdel and predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643a8a8",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c index, ibs\n",
    "# Collect test C-index and IBS scores for all models\n",
    "\n",
    "# Cox model\n",
    "cox_test_c_index = cox_test_predictions['c_index']\n",
    "cox_test_ibs = cox_test_predictions['ibs']\n",
    "\n",
    "# Random Survival Forest\n",
    "rsf_test_c_index = rsf_test_predictions['c_index']\n",
    "rsf_test_ibs = rsf_test_predictions['ibs']\n",
    "\n",
    "# XGBSE\n",
    "xgbse_test_c_index = xgbse_test_predictions['c_index']\n",
    "xgbse_test_ibs = xgbse_ibs_score\n",
    "\n",
    "# DeepHit\n",
    "deephit_test_c_index = deephit_test_predictions['c_index']\n",
    "deephit_test_ibs = deephit_ibs_score\n",
    "\n",
    "# DeepSurv\n",
    "deepsurv_test_c_index = deepsurv_test_predictions['c_index']\n",
    "deepsurv_test_ibs = deepsurv_test_predictions['ibs']\n",
    "\n",
    "# show results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Cox', 'Random Survival Forest', 'XGBSE', 'DeepHit', 'DeepSurv'],\n",
    "    'Test C-index': [\n",
    "        cox_test_c_index,\n",
    "        rsf_test_c_index,\n",
    "        xgbse_test_c_index,\n",
    "        deephit_test_c_index,\n",
    "        deepsurv_test_c_index\n",
    "    ],\n",
    "    'Test IBS': [\n",
    "        cox_test_ibs,\n",
    "        rsf_test_ibs,\n",
    "        xgbse_test_ibs,\n",
    "        deephit_test_ibs,\n",
    "        deepsurv_test_ibs\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdaef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.1)\n",
    "\n",
    "# Global rcParams\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.labelsize': 11,\n",
    "    'legend.frameon': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'lines.linewidth': 2,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman', 'Times', 'serif']\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "# Consistent colors\n",
    "COLORS = ['#2E86C1', '#E74C3C', '#28B463', '#F39C12', '#8E44AD']\n",
    "sns.set_palette(COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf20fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp the loghazar models\n",
    "cox_test_risks_exp = np.exp(cox_test_risks)\n",
    "deepsurv_test_risks_exp = np.exp(deepsurv_test_risks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cd7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plots, i use mostly LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f187d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk score distributions\n",
    "# KDE plots comparing risk score distributions for repurchase (event==1) vs non-repurchase (event==0)\n",
    "\n",
    "model_names = [\n",
    "    (\"Cox\", cox_test_risks_exp),\n",
    "    (\"RSF\", rsf_test_risks),\n",
    "    (\"XGBSE\", xgbse_test_risks),\n",
    "    (\"DeepHit\", deephit_test_risks),\n",
    "    (\"DeepSurv\", deepsurv_test_risks_exp)\n",
    "]\n",
    "\n",
    "event = y_test['event'].values\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for i, (name, risks) in enumerate(model_names):\n",
    "    ax = axes[i]\n",
    "    # to numpy array for indexing\n",
    "    risks_np = np.asarray(risks)\n",
    "    sns.kdeplot(risks_np[event == 1], label=\"Repurchase (event=1)\", fill=True, color=\"tab:blue\", ax=ax)\n",
    "    sns.kdeplot(risks_np[event == 0], label=\"No Repurchase (event=0)\", fill=True, color=\"tab:orange\", ax=ax)\n",
    "    ax.set_title(f\"{name}\")\n",
    "    ax.set_xlabel(\"Risk Score\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "# legend below the plots\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "def plot_calibration_on_ax(ax, model_name, predictions, pred_type, y_test_data, is_first_plot=False):\n",
    "    time_points = [90, 180, 360]\n",
    "    colors = ['#FFC300',       '#FF5733',        '#8E44AD']\n",
    "    linestyles = ['-', '-', '-']\n",
    "    \n",
    "    diag_label = 'Perfect Calibration' if is_first_plot else '_nolegend_'\n",
    "    ax.plot([0, 1], [0, 1], 'k', linestyle=':', label='Perfect calibration', linewidth=0.8)\n",
    "\n",
    "    for i, t0 in enumerate(time_points):\n",
    "        # get survival probabilities based on prediction type\n",
    "        if pred_type == 'funcs':\n",
    "            survival_probs_at_t0 = np.array([fn(t0) for fn in predictions])\n",
    "        elif pred_type == 'df':\n",
    "            survival_probs_at_t0 = predictions[float(t0) if float(t0) in predictions.columns else int(t0)]\n",
    "        elif pred_type == 'df_transposed':\n",
    "            survival_probs_at_t0 = predictions.T[float(t0)]\n",
    "        \n",
    "        event_probs_at_t0 = 1 - survival_probs_at_t0\n",
    "        \n",
    "        # calculation logic\n",
    "        cal_df = pd.DataFrame({\n",
    "            'predicted_prob': event_probs_at_t0,\n",
    "            'time': y_test_data['time'],\n",
    "            'event': y_test_data['event']\n",
    "        })\n",
    "        try:\n",
    "            cal_df['prob_bin'] = pd.qcut(cal_df['predicted_prob'], q=10, labels=False, duplicates='drop')\n",
    "        except ValueError:\n",
    "            cal_df['prob_bin'] = pd.cut(cal_df['predicted_prob'], bins=10, labels=False, include_lowest=True)\n",
    "        \n",
    "        binned_groups = cal_df.groupby('prob_bin')\n",
    "        mean_predicted_prob = binned_groups['predicted_prob'].mean()\n",
    "        \n",
    "        observed_frequency = []\n",
    "        for name, group in binned_groups:\n",
    "            kmf = KaplanMeierFitter()\n",
    "            kmf.fit(group['time'], event_observed=group['event'])\n",
    "            observed_frequency.append(1 - kmf.predict(t0, interpolate=True))\n",
    "\n",
    "        # plotting\n",
    "        sorted_indices = mean_predicted_prob.argsort()\n",
    "        ax.plot(mean_predicted_prob.iloc[sorted_indices], pd.Series(observed_frequency).iloc[sorted_indices],\n",
    "                c=colors[i],\n",
    "                linestyle=linestyles[i],\n",
    "                linewidth=3,\n",
    "                label=f'{t0} days')\n",
    "\n",
    "    # subplot formatting\n",
    "    upper_limit = 0.35\n",
    "    ax.set_xlim(0, upper_limit)\n",
    "    ax.set_ylim(0, upper_limit)\n",
    "    ax.set_title(f'{model_name}')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True, linestyle='--', alpha=0.2)\n",
    "    \n",
    "\n",
    "# CREATE FIGURE AND PLOT MODELS \n",
    "\n",
    "\n",
    "# figure with 1 row and 5 columns\n",
    "fig, axes = plt.subplots(1, 5, figsize=(24, 5), sharey=True)\n",
    "\n",
    "# models, predictions, and prediction types\n",
    "models_to_plot = [\n",
    "    ('Cox', cox_surv_funcs, 'funcs'),\n",
    "    ('RSF', rsf_surv_funcs, 'funcs'),\n",
    "    ('XGBSE', xgbse_test_survival_probs, 'df'),\n",
    "    ('DeepHit', deephit_test_surv_df, 'df'),\n",
    "    ('DeepSurv', deepsurv_test_surv_df, 'df_transposed')\n",
    "]\n",
    "\n",
    "# loop through models and plot on respective axes\n",
    "for i, (model_name, preds, pred_type) in enumerate(models_to_plot):\n",
    "    plot_calibration_on_ax(axes[i], model_name, preds, pred_type, y_test, is_first_plot=(i==0))\n",
    "\n",
    "# figure formatting\n",
    "# shared y-axis label\n",
    "axes[0].set_ylabel('Observed Frequency of Repurchase')\n",
    "# shared x-axis label in the middle\n",
    "fig.text(0.5, 0.05, 'Mean Predicted Probability of Repurchase', ha='center', va='center', fontsize=12)\n",
    "\n",
    "# a single legend for the entire figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=4, fontsize=12)\n",
    "\n",
    "# adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)  # room for the legend at the bottom\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25884072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "ROC_COLORS = ['#FFC300',       '#FF5733',        '#8E44AD']\n",
    "\n",
    "models_to_plot = [\n",
    "    ('Cox', cox_test_risks), \n",
    "    ('RSF', rsf_test_risks),\n",
    "    ('XGBSE', xgbse_test_risks), \n",
    "    ('DeepHit', deephit_test_risks),\n",
    "    ('DeepSurv', deepsurv_test_risks)\n",
    "]\n",
    "\n",
    "# pre-calculate AUC curves and mean values\n",
    "evaluation_times = np.arange(int(y_test['time'].min()), int(y_test['time'].max()), 10)\n",
    "all_auc_scores = pd.DataFrame(index=evaluation_times)\n",
    "mean_aucs = {}\n",
    "\n",
    "print(\"calculating cumulative/dynamic AUC over time\")\n",
    "for model_name, risks in models_to_plot:\n",
    "    auc_curve, integrated_mean_auc = cumulative_dynamic_auc(\n",
    "        survival_train=y_train_struct, survival_test=y_test_struct,\n",
    "        estimate=risks, times=evaluation_times\n",
    "    )\n",
    "    all_auc_scores[model_name] = auc_curve\n",
    "    mean_aucs[model_name] = integrated_mean_auc\n",
    "print(\"calculation complete\")\n",
    "\n",
    "\n",
    "# HELPER FUNCTION FOR ROC SNAPSHOTS\n",
    "\n",
    "def time_dependent_roc_at_t(y_true, risk_scores, time_point):\n",
    "    events_by_t = (y_true['time'] <= time_point) & (y_true['event'] == 1)\n",
    "    no_events_by_t = y_true['time'] > time_point\n",
    "    if events_by_t.sum() == 0 or no_events_by_t.sum() == 0: return np.array([0, 1]), np.array([0, 1])\n",
    "    y_true_binary = np.concatenate([np.ones(events_by_t.sum()), np.zeros(no_events_by_t.sum())])\n",
    "    y_scores_binary = np.concatenate([risk_scores[events_by_t], risk_scores[no_events_by_t]])\n",
    "    return roc_curve(y_true_binary, y_scores_binary)\n",
    "\n",
    "\n",
    "# 2x5 FIGURE \n",
    "fig, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False, sharey=False)\n",
    "\n",
    "for i, (model_name, risks) in enumerate(models_to_plot):\n",
    "    # axes for this model\n",
    "    ax_top = axes[0, i]\n",
    "    ax_bottom = axes[1, i]\n",
    "    \n",
    "    # AUC over time (top) \n",
    "    model_mean_auc = mean_aucs[model_name]\n",
    "    ax_top.axhline(model_mean_auc, color='gray', linestyle='--', linewidth=1.5, alpha=0.9,\n",
    "                   label=f'Mean AUC = {model_mean_auc:.3f}')\n",
    "    ax_top.plot(evaluation_times, all_auc_scores[model_name], color=COLORS[0], linewidth=2.5)\n",
    "    ax_top.set_title(model_name)\n",
    "    ax_top.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax_top.legend(loc='lower right', fontsize=9)\n",
    "    ax_top.set_ylim(0.45, 1.0)\n",
    "\n",
    "    # ROC curves (bottom)\n",
    "    time_points = [90, 180, 360]\n",
    "    for j, t in enumerate(time_points):\n",
    "        fpr, tpr, _ = time_dependent_roc_at_t(y_test, risks, t)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        ax_bottom.plot(fpr, tpr, color=ROC_COLORS[j], label=f'AUC at {t} days = {auc_score:.3f}', lw=2)\n",
    "    \n",
    "    ax_bottom.plot([0, 1], [0, 1], 'k--', alpha=0.6)\n",
    "    ax_bottom.set_aspect('equal', adjustable='box')\n",
    "    ax_bottom.legend(fontsize=9)\n",
    "\n",
    "# figure formatting\n",
    "# shared labels for rows and columns\n",
    "for i in range(5):\n",
    "    axes[1, i].set_xlabel('False Positive Rate') # Label bottom row\n",
    "    axes[0, i].sharey(axes[0, 0]) # Share Y-axis for top row\n",
    "    axes[1, i].sharey(axes[1, 0]) # Share Y-axis for bottom row\n",
    "    axes[1, i].sharex(axes[1, 0]) # Share X-axis for bottom row\n",
    "\n",
    "axes[0, 0].set_ylabel('Cumulative/Dynamic AUC')\n",
    "axes[1, 0].set_ylabel('True Positive Rate')\n",
    "\n",
    "# adjust layout\n",
    "plt.tight_layout(rect=[0.02, 0.0, 1, 0.95]) # make space for title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02864229",
   "metadata": {},
   "source": [
    "## Model explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import survshap\n",
    "from survshap import SurvivalModelExplainer, ModelSurvSHAP\n",
    "from sksurv.util import Surv\n",
    "\n",
    "def stratified_sample(X, y, n_samples=150, random_state=42):\n",
    "    event_rate = y['event'].mean()\n",
    "    n_event_1 = int(n_samples * event_rate)\n",
    "    n_event_0 = n_samples - n_event_1\n",
    "    \n",
    "    indices_1 = X[y['event'] == 1].index\n",
    "    indices_0 = X[y['event'] == 0].index\n",
    "    \n",
    "    sample_1 = X.loc[indices_1].sample(n=min(n_event_1, len(indices_1)), random_state=random_state)\n",
    "    sample_0 = X.loc[indices_0].sample(n=min(n_event_0, len(indices_0)), random_state=random_state)\n",
    "    \n",
    "    return pd.concat([sample_1, sample_0])\n",
    "\n",
    "# sample data\n",
    "X_train_sample = stratified_sample(X_train, y_train, n_samples=150)\n",
    "X_test_sample = stratified_sample(X_test, y_test, n_samples=150)\n",
    "\n",
    "# convert to structured arrays\n",
    "y_train_sample = Surv.from_arrays(\n",
    "    y_train.loc[X_train_sample.index, 'event'].astype(bool),\n",
    "    y_train.loc[X_train_sample.index, 'time']\n",
    ")\n",
    "\n",
    "y_test_sample = Surv.from_arrays(\n",
    "    y_test.loc[X_test_sample.index, 'event'].astype(bool),\n",
    "    y_test.loc[X_test_sample.index, 'time']\n",
    ")\n",
    "\n",
    "# create explainer and fit\n",
    "explainer = SurvivalModelExplainer(\n",
    "    model=rsf_model, \n",
    "    data=X_train_sample, \n",
    "    y=y_train_sample\n",
    ")\n",
    "\n",
    "rsf_model_survshap = ModelSurvSHAP(calculation_method=\"sampling\", B=20, random_state=1212)\n",
    "rsf_model_survshap.fit(explainer=explainer, new_observations=X_test_sample)\n",
    "print(\"ModelSurvSHAP fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae226d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vars = 8\n",
    "df_to_plot = rsf_model_survshap.result.head(max_vars)\n",
    "time_cols = [col for col in df_to_plot.columns if col.startswith('t = ')]\n",
    "time_values = [float(col.split('=')[1]) for col in time_cols]\n",
    "\n",
    "# plotting\n",
    "\n",
    "# color palette\n",
    "colors = ['#ae2c87', '#46bac2', '#ffa58c', '#f05a71', '#8bdcbe', '#4378bf', '#FED61E', '#371ea3']\n",
    "\n",
    "# figure and axes\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# loop through each feature and plot its line\n",
    "for i, (index, row) in enumerate(df_to_plot.iterrows()):\n",
    "    feature_name = row['variable_name']\n",
    "    shap_values = row[time_cols].values\n",
    "    \n",
    "    ax.plot(\n",
    "        time_values, \n",
    "        shap_values, \n",
    "        label=feature_name, \n",
    "        color=colors[i % len(colors)],\n",
    "        linewidth=2.5, \n",
    "        alpha=0.9      \n",
    "    )\n",
    "\n",
    "# customization\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('Time', fontsize=12)\n",
    "ax.set_ylabel('mean(|SHAP value|)', fontsize=12)\n",
    "\n",
    "# frameless legend below plot\n",
    "ax.legend(\n",
    "    loc='upper center', \n",
    "    bbox_to_anchor=(0.5, -0.1), \n",
    "    ncol=8,                   \n",
    "    frameon=False,            \n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# clean grid and spines\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='grey', alpha=0.3)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "# space for the legend at the bottom\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_survshap_beeswarm(model_survshap, top_n=8):\n",
    "    # top features based on aggregated change\n",
    "    importance_df = model_survshap.result[['variable_name', 'aggregated_change']].copy()\n",
    "    importance_df.columns = ['feature', 'importance']\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    top_features = importance_df.head(top_n)['feature'].tolist()\n",
    "    \n",
    "    # extract SHAP values for each observation\n",
    "    full_result_b0 = model_survshap.full_result[model_survshap.full_result['B'] == 0].copy()\n",
    "    time_columns = [col for col in full_result_b0.columns if col.startswith('t = ')]\n",
    "    \n",
    "    plot_data = []\n",
    "    for idx, row in full_result_b0.iterrows():\n",
    "        if row['variable_name'] in top_features:\n",
    "            # INVERT the SHAP values for intuitive meaning\n",
    "            mean_shap = -row[time_columns].mean()\n",
    "            plot_data.append({\n",
    "                'feature': row['variable_name'],\n",
    "                'aggregated_shap': mean_shap,\n",
    "                'feature_value': row['variable_value']\n",
    "            })\n",
    "    \n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    \n",
    "\n",
    "    # create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8),\n",
    "                                   gridspec_kw={'width_ratios': [1, 2.5]},\n",
    "                                   sharey=True)\n",
    "    \n",
    "    # sorted ascending for correct order in plot\n",
    "    importance_sorted = importance_df.head(top_n).sort_values('importance', ascending=True)\n",
    "    feature_order = importance_sorted['feature'].tolist()\n",
    "\n",
    "    # left plot: lollipop chart\n",
    "    ax1.hlines(\n",
    "        y=importance_sorted['feature'],\n",
    "        xmin=0,\n",
    "        xmax=importance_sorted['importance'],\n",
    "        color='#4682B4',\n",
    "        alpha=0.6,\n",
    "        linewidth=2\n",
    "    )\n",
    "    ax1.scatter(\n",
    "        x=importance_sorted['importance'],\n",
    "        y=importance_sorted['feature'],\n",
    "        s=100,\n",
    "        color='#4682B4',\n",
    "        alpha=0.9,\n",
    "        zorder=3\n",
    "    )\n",
    "    \n",
    "    # right Plot: beeswarm\n",
    "    # normalize for coloring (0 to 1)\n",
    "    df_plot['feature_value_norm'] = 0.5\n",
    "    for feature in top_features:\n",
    "        mask = df_plot['feature'] == feature\n",
    "        if mask.sum() > 0:\n",
    "            vals = df_plot.loc[mask, 'feature_value'].values\n",
    "            if vals.std() > 0:\n",
    "                normalized = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "                df_plot.loc[mask, 'feature_value_norm'] = normalized\n",
    "    \n",
    "    # plot with jitter\n",
    "    np.random.seed(42)\n",
    "    # feature_order ensures beeswarm aligns with lollipops\n",
    "    for i, feature in enumerate(feature_order):\n",
    "        feature_data = df_plot[df_plot['feature'] == feature]\n",
    "        if len(feature_data) > 0:\n",
    "            y_jitter = np.random.normal(0, 0.08, len(feature_data))\n",
    "            y_positions = i + y_jitter\n",
    "            \n",
    "            # keep a reference to the scatter plot for the colorbar\n",
    "            scatter = ax2.scatter(\n",
    "                feature_data['aggregated_shap'].values,\n",
    "                y_positions,\n",
    "                c=feature_data['feature_value_norm'].values,\n",
    "                cmap='RdBu_r', vmin=0, vmax=1,\n",
    "                s=50, alpha=0.6,\n",
    "                edgecolors='none'\n",
    "            )\n",
    "            \n",
    "    # styling\n",
    "\n",
    "    # left plot (ax1)\n",
    "    ax1.set_xlabel('Average |Aggregated SurvSHAP(t)| Value')\n",
    "    ax1.set_title('(a)', loc='center', y=-0.1, weight='bold', fontsize=12)\n",
    "    ax1.tick_params(axis='y', length=0) # Hide tick marks on y-axis\n",
    "    ax1.spines[['top', 'right', 'left']].set_visible(False)\n",
    "    ax1.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.25)\n",
    "    ax1.set_xlim(0)\n",
    "\n",
    "    # right plot (ax2)\n",
    "    ax2.set_xlabel('Aggregated SurvSHAP(t) Value')\n",
    "    ax2.set_title('(b)', loc='center', y=-0.1, weight='bold', fontsize=12)\n",
    "    ax2.axvline(x=0, color='grey', linestyle='--', linewidth=1.5)\n",
    "    ax2.spines[['top', 'right', 'left']].set_visible(False)\n",
    "    ax2.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.25)\n",
    "    \n",
    "    # hide the tick marks\n",
    "    ax2.tick_params(axis='y', length=0)\n",
    "    \n",
    "    # clean colorbar\n",
    "    cbar = fig.colorbar(scatter, ax=ax2, aspect=40, pad=0.03)\n",
    "    cbar.set_label('Feature Value (High / Low)', rotation=270, labelpad=15)\n",
    "    cbar.outline.set_visible(False)\n",
    "    \n",
    "    # layout adjustment\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94]) # Adjust rect to make space for suptitle\n",
    "    plt.show()\n",
    "    \n",
    "    return df_plot\n",
    "\n",
    "df_inverted_plot_data = create_inverted_survshap_beeswarm(rsf_model_survshap, top_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all best parameters for appendix\n",
    "print(\"BEST HYPERPARAMETERS FOR ALL MODELS\\n\")\n",
    "\n",
    "# cox model\n",
    "print(\"1. COX PROPORTIONAL HAZARDS MODEL\")\n",
    "print(\"-\" * 40)\n",
    "with open('../../models/best_cox_params.json', 'r') as f:\n",
    "    cox_params = json.load(f)\n",
    "for param, value in cox_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print()\n",
    "\n",
    "# random survival forest\n",
    "print(\"2. RANDOM SURVIVAL FOREST\")\n",
    "print(\"-\" * 40)\n",
    "with open('../../models/best_rsf_params.json', 'r') as f:\n",
    "    rsf_params = json.load(f)\n",
    "for param, value in rsf_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print()\n",
    "\n",
    "# xgbse\n",
    "print(\"3. XGBSE (XGBoost Survival Embeddings)\")\n",
    "print(\"-\" * 40)\n",
    "with open('../../models/best_xgbse_params.json', 'r') as f:\n",
    "    xgbse_params = json.load(f)\n",
    "for param, value in xgbse_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print()\n",
    "\n",
    "# deephit\n",
    "print(\"4. DEEPHIT\")\n",
    "print(\"-\" * 40)\n",
    "with open('../../models/best_deephit_params.json', 'r') as f:\n",
    "    deephit_params = json.load(f)\n",
    "for param, value in deephit_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "print()\n",
    "\n",
    "# deepsurv\n",
    "print(\"5. DEEPSURV\")\n",
    "print(\"-\" * 40)\n",
    "with open('../../models/best_deepsurv_params.json', 'r') as f:\n",
    "    deepsurv_params = json.load(f)\n",
    "for param, value in deepsurv_params.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full SurvSHAP results df\n",
    "df = rsf_model_survshap.result\n",
    "\n",
    "# sort by aggregated_change (feature importance)\n",
    "df_sorted = df.sort_values('aggregated_change', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, max(6, 0.4 * len(df_sorted))))\n",
    "plt.barh(df_sorted['variable_name'], df_sorted['aggregated_change'], color='#4682B4', alpha=0.8)\n",
    "plt.xlabel('Aggregated |SurvSHAP(t)| Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance (Aggregated SurvSHAP) - Full List')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survenv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
